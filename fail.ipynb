{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7751000</td>\n",
       "      <td>M-137 was a state trunkline highway in the US ...</td>\n",
       "      <td>M-137 (Michigan highway)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7751001</td>\n",
       "      <td>In sociology, dynamic density refers to the co...</td>\n",
       "      <td>Dynamic density</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7751042</td>\n",
       "      <td>Bert Robert Shepard (June 20, 1920 – June 16, ...</td>\n",
       "      <td>Bert Shepard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7751048</td>\n",
       "      <td>Marc Fein (born Marc Alan Fein October 21, 196...</td>\n",
       "      <td>Marc Fein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7751062</td>\n",
       "      <td>Ghelamco Arena panorama indoor. The Ghelamco A...</td>\n",
       "      <td>Ghelamco Arena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>7853026</td>\n",
       "      <td>State Highway 204 (SH 204) is a Texas state hi...</td>\n",
       "      <td>Texas State Highway 204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>7853030</td>\n",
       "      <td>Shrimp chips may refer to: *Prawn cracker, an ...</td>\n",
       "      <td>Shrimp chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>7853033</td>\n",
       "      <td>Martin Hhaway Sulle (born 28 December 1982) is...</td>\n",
       "      <td>Martin Sulle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>7853047</td>\n",
       "      <td>Krak des Chevaliers was built during the 12th ...</td>\n",
       "      <td>List of Crusader castles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>7853061</td>\n",
       "      <td>Wardner is a side-scrolling platform game deve...</td>\n",
       "      <td>Wardner (video game)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9982 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                               text  \\\n",
       "0     7751000  M-137 was a state trunkline highway in the US ...   \n",
       "1     7751001  In sociology, dynamic density refers to the co...   \n",
       "2     7751042  Bert Robert Shepard (June 20, 1920 – June 16, ...   \n",
       "3     7751048  Marc Fein (born Marc Alan Fein October 21, 196...   \n",
       "4     7751062  Ghelamco Arena panorama indoor. The Ghelamco A...   \n",
       "...       ...                                                ...   \n",
       "9977  7853026  State Highway 204 (SH 204) is a Texas state hi...   \n",
       "9978  7853030  Shrimp chips may refer to: *Prawn cracker, an ...   \n",
       "9979  7853033  Martin Hhaway Sulle (born 28 December 1982) is...   \n",
       "9980  7853047  Krak des Chevaliers was built during the 12th ...   \n",
       "9981  7853061  Wardner is a side-scrolling platform game deve...   \n",
       "\n",
       "                         title  \n",
       "0     M-137 (Michigan highway)  \n",
       "1              Dynamic density  \n",
       "2                 Bert Shepard  \n",
       "3                    Marc Fein  \n",
       "4               Ghelamco Arena  \n",
       "...                        ...  \n",
       "9977   Texas State Highway 204  \n",
       "9978              Shrimp chips  \n",
       "9979              Martin Sulle  \n",
       "9980  List of Crusader castles  \n",
       "9981      Wardner (video game)  \n",
       "\n",
       "[9982 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Path to the JSON file\n",
    "json_file_path = \"kk.json\"\n",
    "\n",
    "# Read the JSON file\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 9982\n",
      "Average word count per row: 625.2353235824484\n",
      "Maximum word count in a row: 29862\n",
      "Minimum word count in a row: 0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of words in each row of the 'text' column\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Display basic information\n",
    "print(\"Total rows:\", len(df))\n",
    "print(\"Average word count per row:\", df['word_count'].mean())\n",
    "print(\"Maximum word count in a row:\", df['word_count'].max())\n",
    "print(\"Minimum word count in a row:\", df['word_count'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34243</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y, or y, is the twenty-fifth and penultimate l...</td>\n",
       "      <td>[ISO basic Latin letters, Vowel letters]</td>\n",
       "      <td>twenty fifth penultimate letter latin alphabet...</td>\n",
       "      <td>[0.20263745, -0.04579359, -0.3257939, 0.115376...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54422412</td>\n",
       "      <td>Y (2017 film)</td>\n",
       "      <td>Y is a 2017 Indian Malayalam-language suspense...</td>\n",
       "      <td>[2017 films, 2010s Malayalam-language films, F...</td>\n",
       "      <td>2017 indian malayalam language suspense thrill...</td>\n",
       "      <td>[0.2645224, -0.44076246, -0.6969259, 0.2976651...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72497275</td>\n",
       "      <td>Y (2022 film)</td>\n",
       "      <td>Y is a 2022 Indian Marathi-language thriller f...</td>\n",
       "      <td>[2020s Marathi-language films]</td>\n",
       "      <td>2022 indian marathi language thriller film dir...</td>\n",
       "      <td>[0.008103508, -0.37812018, -0.61634463, 0.2772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28612155</td>\n",
       "      <td>Y (EP)</td>\n",
       "      <td>Y is the second EP by South Korean boy band MB...</td>\n",
       "      <td>[2010 EPs, MBLAQ EPs, Korean- language EPs]</td>\n",
       "      <td>second ep south korean boy band mblaq released...</td>\n",
       "      <td>[0.31747183, -0.32646042, -0.58376694, 0.19630...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3336727</td>\n",
       "      <td>Y (album)</td>\n",
       "      <td>Y is the debut studio album of English post-pu...</td>\n",
       "      <td>[1979 debut albums, The Pop Group albums, Rada...</td>\n",
       "      <td>debut studio album english post punk band pop ...</td>\n",
       "      <td>[0.21296582, -0.35025266, -0.47778022, -0.1460...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47644</th>\n",
       "      <td>535114</td>\n",
       "      <td>Yǐn (surname)</td>\n",
       "      <td>Yin () is a Chinese surname. In 800 BCE, Bo Ji...</td>\n",
       "      <td>[Chinese-language surnames, Individual Chinese...</td>\n",
       "      <td>yin chinese surname 800 bce bo jifu renowned j...</td>\n",
       "      <td>[0.2682601, -0.23937249, -0.37670502, -0.10721...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47645</th>\n",
       "      <td>18849541</td>\n",
       "      <td>Yəhərçi Qazaxlar</td>\n",
       "      <td>Yəhərçi Qazaxlar (also, Kyrmyzy-Kazakhlar, Yag...</td>\n",
       "      <td>[Populated places in Goranboy District]</td>\n",
       "      <td>yəhərçi qazaxlar also kyrmyzy kazakhlar yagarc...</td>\n",
       "      <td>[-0.0763359, -0.486903, -0.3944276, -0.0762714...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47646</th>\n",
       "      <td>19738160</td>\n",
       "      <td>Yếm</td>\n",
       "      <td>A yếm or áo yếm (, chữ Nôm: 裺) is a traditiona...</td>\n",
       "      <td>[Undergarments, Vietnamese clothing, Vietnames...</td>\n",
       "      <td>yếm áo yếm chữ nôm 裺 traditional vietnamese un...</td>\n",
       "      <td>[0.16064724, -0.37610123, -0.30872235, 0.26827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47647</th>\n",
       "      <td>22133528</td>\n",
       "      <td>Yến Dương</td>\n",
       "      <td>{{Infobox settlement |name = Yến Dương |other_...</td>\n",
       "      <td>[Populated places in Bắc Kạn province, Commune...</td>\n",
       "      <td>infobox settlement name yến dương other_name n...</td>\n",
       "      <td>[-0.066104345, -0.41770568, -0.32169256, 0.114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47648</th>\n",
       "      <td>22134126</td>\n",
       "      <td>Yến Lạc</td>\n",
       "      <td>{{Infobox settlement |name = Yến Lạc |other_na...</td>\n",
       "      <td>[Populated places in Bắc Kạn province, Commune...</td>\n",
       "      <td>infobox settlement name yến lạc other_name nat...</td>\n",
       "      <td>[0.09477074, -0.44810683, -0.3087562, 0.152675...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47649 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id             title  \\\n",
       "0         34243                 Y   \n",
       "1      54422412     Y (2017 film)   \n",
       "2      72497275     Y (2022 film)   \n",
       "3      28612155            Y (EP)   \n",
       "4       3336727         Y (album)   \n",
       "...         ...               ...   \n",
       "47644    535114     Yǐn (surname)   \n",
       "47645  18849541  Yəhərçi Qazaxlar   \n",
       "47646  19738160               Yếm   \n",
       "47647  22133528         Yến Dương   \n",
       "47648  22134126           Yến Lạc   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Y, or y, is the twenty-fifth and penultimate l...   \n",
       "1      Y is a 2017 Indian Malayalam-language suspense...   \n",
       "2      Y is a 2022 Indian Marathi-language thriller f...   \n",
       "3      Y is the second EP by South Korean boy band MB...   \n",
       "4      Y is the debut studio album of English post-pu...   \n",
       "...                                                  ...   \n",
       "47644  Yin () is a Chinese surname. In 800 BCE, Bo Ji...   \n",
       "47645  Yəhərçi Qazaxlar (also, Kyrmyzy-Kazakhlar, Yag...   \n",
       "47646  A yếm or áo yếm (, chữ Nôm: 裺) is a traditiona...   \n",
       "47647  {{Infobox settlement |name = Yến Dương |other_...   \n",
       "47648  {{Infobox settlement |name = Yến Lạc |other_na...   \n",
       "\n",
       "                                              categories  \\\n",
       "0               [ISO basic Latin letters, Vowel letters]   \n",
       "1      [2017 films, 2010s Malayalam-language films, F...   \n",
       "2                         [2020s Marathi-language films]   \n",
       "3            [2010 EPs, MBLAQ EPs, Korean- language EPs]   \n",
       "4      [1979 debut albums, The Pop Group albums, Rada...   \n",
       "...                                                  ...   \n",
       "47644  [Chinese-language surnames, Individual Chinese...   \n",
       "47645            [Populated places in Goranboy District]   \n",
       "47646  [Undergarments, Vietnamese clothing, Vietnames...   \n",
       "47647  [Populated places in Bắc Kạn province, Commune...   \n",
       "47648  [Populated places in Bắc Kạn province, Commune...   \n",
       "\n",
       "                                            cleaned_text  \\\n",
       "0      twenty fifth penultimate letter latin alphabet...   \n",
       "1      2017 indian malayalam language suspense thrill...   \n",
       "2      2022 indian marathi language thriller film dir...   \n",
       "3      second ep south korean boy band mblaq released...   \n",
       "4      debut studio album english post punk band pop ...   \n",
       "...                                                  ...   \n",
       "47644  yin chinese surname 800 bce bo jifu renowned j...   \n",
       "47645  yəhərçi qazaxlar also kyrmyzy kazakhlar yagarc...   \n",
       "47646  yếm áo yếm chữ nôm 裺 traditional vietnamese un...   \n",
       "47647  infobox settlement name yến dương other_name n...   \n",
       "47648  infobox settlement name yến lạc other_name nat...   \n",
       "\n",
       "                                              embeddings  \n",
       "0      [0.20263745, -0.04579359, -0.3257939, 0.115376...  \n",
       "1      [0.2645224, -0.44076246, -0.6969259, 0.2976651...  \n",
       "2      [0.008103508, -0.37812018, -0.61634463, 0.2772...  \n",
       "3      [0.31747183, -0.32646042, -0.58376694, 0.19630...  \n",
       "4      [0.21296582, -0.35025266, -0.47778022, -0.1460...  \n",
       "...                                                  ...  \n",
       "47644  [0.2682601, -0.23937249, -0.37670502, -0.10721...  \n",
       "47645  [-0.0763359, -0.486903, -0.3944276, -0.0762714...  \n",
       "47646  [0.16064724, -0.37610123, -0.30872235, 0.26827...  \n",
       "47647  [-0.066104345, -0.41770568, -0.32169256, 0.114...  \n",
       "47648  [0.09477074, -0.44810683, -0.3087562, 0.152675...  \n",
       "\n",
       "[47649 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Path to your Parquet file\n",
    "file_path = 'y.parquet'\n",
    "\n",
    "# Read the Parquet file and convert it to a Pandas DataFrame\n",
    "df = pq.read_table(file_path).to_pandas()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860524</td>\n",
       "      <td>L</td>\n",
       "      <td>L, or l, is the twelfth letter in the Latin al...</td>\n",
       "      <td>[ISO basic Latin letters]</td>\n",
       "      <td>l l twelfth letter latin alphabet used modern ...</td>\n",
       "      <td>[0.3376371, -0.10313419, -0.47920448, 0.036238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7167147</td>\n",
       "      <td>L &amp; N Marine Terminal Building</td>\n",
       "      <td>The L &amp; N Marine Terminal Building is a histor...</td>\n",
       "      <td>[Buildings and structures in Pensacola, Florid...</td>\n",
       "      <td>l n marine terminal building historic site pen...</td>\n",
       "      <td>[-0.004209465, -0.4288666, -0.32924867, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28519613</td>\n",
       "      <td>L (Ayumi Hamasaki EP)</td>\n",
       "      <td>L is the 50th single (51st overall) by Japanes...</td>\n",
       "      <td>[2010 singles, Oricon Weekly number-one singles]</td>\n",
       "      <td>l 50th single 51st overall japanese singer son...</td>\n",
       "      <td>[0.08933294, 0.02698402, -0.667453, 0.32261816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9893990</td>\n",
       "      <td>L (Death Note)</td>\n",
       "      <td>,Ohba, Tsugumi and Takeshi Obata. \"Character F...</td>\n",
       "      <td>[Martial artist characters in anime and manga,...</td>\n",
       "      <td>ohba tsugumi takeshi obata character file 2 l ...</td>\n",
       "      <td>[-0.012304991, -0.4061539, -0.7352755, 0.11444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36259475</td>\n",
       "      <td>L (French singer)</td>\n",
       "      <td>L is the stage name of Raphaële Lannadère,\"L\",...</td>\n",
       "      <td>[1981 births, French women singer-songwriters,...</td>\n",
       "      <td>l stage name raphaële lannadère l tôt ou tard ...</td>\n",
       "      <td>[0.26492855, -0.69320434, -0.86082757, 0.28035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364438</th>\n",
       "      <td>45466710</td>\n",
       "      <td>Lục Xuân Hưng</td>\n",
       "      <td>Lục Xuân Hưng (born 15 April 1995) is a Vietna...</td>\n",
       "      <td>[1995 births, Living people, Vietnamese footba...</td>\n",
       "      <td>lục xuân hưng born 15 april 1995 vietnamese fo...</td>\n",
       "      <td>[-0.14476362, -0.8220984, -1.316604, -0.499117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364439</th>\n",
       "      <td>15527229</td>\n",
       "      <td>Lục Yên district</td>\n",
       "      <td>Lục Yên is a rural district of Yên Bái provinc...</td>\n",
       "      <td>[Districts of Yên Bái province, Yên Bái province]</td>\n",
       "      <td>lục yên rural district yên bái province northe...</td>\n",
       "      <td>[0.09132685, -0.620817, -0.32133546, 0.2334157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364440</th>\n",
       "      <td>1858789</td>\n",
       "      <td>Lục bát</td>\n",
       "      <td>Lục bát (, ) is a traditional Vietnamese verse...</td>\n",
       "      <td>[Poetic forms, Vietnamese literary genres, Vie...</td>\n",
       "      <td>lục bát traditional vietnamese verse form hist...</td>\n",
       "      <td>[-0.14366665, 0.012986276, -0.38193414, 0.0137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364441</th>\n",
       "      <td>37953650</td>\n",
       "      <td>Lục súc tranh công</td>\n",
       "      <td>Lục súc tranh công (六畜爭功 \"The Quarrel of the S...</td>\n",
       "      <td>[Vietnamese poems]</td>\n",
       "      <td>lục súc tranh công 六畜爭功 quarrel six beasts cla...</td>\n",
       "      <td>[-0.43239307, -0.24961491, -0.24945787, 0.2566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364442</th>\n",
       "      <td>11325389</td>\n",
       "      <td>Lữ Mộng Lan</td>\n",
       "      <td>thumb|Lữ Mộng Lan Lieutenant General Lữ Mộng L...</td>\n",
       "      <td>[1927 births, 2021 deaths, Army of the Republi...</td>\n",
       "      <td>thumb lữ mộng lan lieutenant general lữ mộng l...</td>\n",
       "      <td>[0.3167757, -0.64930534, -0.6465167, 0.2288338...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364443 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                           title  \\\n",
       "0        4860524                               L   \n",
       "1        7167147  L & N Marine Terminal Building   \n",
       "2       28519613           L (Ayumi Hamasaki EP)   \n",
       "3        9893990                  L (Death Note)   \n",
       "4       36259475               L (French singer)   \n",
       "...          ...                             ...   \n",
       "364438  45466710                   Lục Xuân Hưng   \n",
       "364439  15527229                Lục Yên district   \n",
       "364440   1858789                         Lục bát   \n",
       "364441  37953650              Lục súc tranh công   \n",
       "364442  11325389                     Lữ Mộng Lan   \n",
       "\n",
       "                                                     text  \\\n",
       "0       L, or l, is the twelfth letter in the Latin al...   \n",
       "1       The L & N Marine Terminal Building is a histor...   \n",
       "2       L is the 50th single (51st overall) by Japanes...   \n",
       "3       ,Ohba, Tsugumi and Takeshi Obata. \"Character F...   \n",
       "4       L is the stage name of Raphaële Lannadère,\"L\",...   \n",
       "...                                                   ...   \n",
       "364438  Lục Xuân Hưng (born 15 April 1995) is a Vietna...   \n",
       "364439  Lục Yên is a rural district of Yên Bái provinc...   \n",
       "364440  Lục bát (, ) is a traditional Vietnamese verse...   \n",
       "364441  Lục súc tranh công (六畜爭功 \"The Quarrel of the S...   \n",
       "364442  thumb|Lữ Mộng Lan Lieutenant General Lữ Mộng L...   \n",
       "\n",
       "                                               categories  \\\n",
       "0                               [ISO basic Latin letters]   \n",
       "1       [Buildings and structures in Pensacola, Florid...   \n",
       "2        [2010 singles, Oricon Weekly number-one singles]   \n",
       "3       [Martial artist characters in anime and manga,...   \n",
       "4       [1981 births, French women singer-songwriters,...   \n",
       "...                                                   ...   \n",
       "364438  [1995 births, Living people, Vietnamese footba...   \n",
       "364439  [Districts of Yên Bái province, Yên Bái province]   \n",
       "364440  [Poetic forms, Vietnamese literary genres, Vie...   \n",
       "364441                                 [Vietnamese poems]   \n",
       "364442  [1927 births, 2021 deaths, Army of the Republi...   \n",
       "\n",
       "                                             cleaned_text  \\\n",
       "0       l l twelfth letter latin alphabet used modern ...   \n",
       "1       l n marine terminal building historic site pen...   \n",
       "2       l 50th single 51st overall japanese singer son...   \n",
       "3       ohba tsugumi takeshi obata character file 2 l ...   \n",
       "4       l stage name raphaële lannadère l tôt ou tard ...   \n",
       "...                                                   ...   \n",
       "364438  lục xuân hưng born 15 april 1995 vietnamese fo...   \n",
       "364439  lục yên rural district yên bái province northe...   \n",
       "364440  lục bát traditional vietnamese verse form hist...   \n",
       "364441  lục súc tranh công 六畜爭功 quarrel six beasts cla...   \n",
       "364442  thumb lữ mộng lan lieutenant general lữ mộng l...   \n",
       "\n",
       "                                               embeddings  \n",
       "0       [0.3376371, -0.10313419, -0.47920448, 0.036238...  \n",
       "1       [-0.004209465, -0.4288666, -0.32924867, -0.054...  \n",
       "2       [0.08933294, 0.02698402, -0.667453, 0.32261816...  \n",
       "3       [-0.012304991, -0.4061539, -0.7352755, 0.11444...  \n",
       "4       [0.26492855, -0.69320434, -0.86082757, 0.28035...  \n",
       "...                                                   ...  \n",
       "364438  [-0.14476362, -0.8220984, -1.316604, -0.499117...  \n",
       "364439  [0.09132685, -0.620817, -0.32133546, 0.2334157...  \n",
       "364440  [-0.14366665, 0.012986276, -0.38193414, 0.0137...  \n",
       "364441  [-0.43239307, -0.24961491, -0.24945787, 0.2566...  \n",
       "364442  [0.3167757, -0.64930534, -0.6465167, 0.2288338...  \n",
       "\n",
       "[364443 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Y is a 2017 Indian Malayalam-language suspense-thriller film written and directed by Sunil Ibrahim. The film was released on 17 November 2017. ==Plot== Arun and Teena, a young couple, were walking down the street, laughing and clicking pictures when some auto-rickshaw drivers mocked them. A few minutes later, a few thugs take illicit photographs of Teena, which angers Arun, and he incites a fight. At Teena\\'s request, Arun stops fighting and walks back while the thugs warn Arun that they will kidnap Teena in front of him. At the same time, a speeding van kidnaps Teena, taking her to a flat nearby where many prominent personalities live. A distraught Arun is unable to find her. With the help of a few auto-rickshaw drivers, they find the flat but cannot go inside as the watchman does not allow them to enter, fearing that it will create chaos for the residents. They decide to call the police. Meanwhile, in the flat, Mohan and his family, consisting of a wife and their daughter, are planning to move to Bangalore. Salim runs an illicit business and is desperate to make a thirty-crore rupee transaction with the help of a Goonda leader. While the Goonda cannot go down as a few other men are waiting for him down the road, he chit-chats with a woman working for Salim. Down the road, a police Sub-inspector questions Arun and others who witnessed Teena\\'s kidnapping. The thugs are waiting for the Goonda leader, and two journalists are secretly watching the drama of the crime and reporting it. Arun does not disclose to the police the nature of his and Teena\\'s relationship. Salim calls the woman working for him and instructs her to release the Goonda leader as he is of no use anymore and to leave him to the thugs waiting for him down the road. In turn, Salim asks another guy, a friend of the Goonda to conduct the transaction on his behalf. He reluctantly accepts. Mohan and his family are packing bags and about to leave. While Arun is helplessly sitting, unable to do anything. The CCTV cameras are turned off on the instructions by Salim, which makes Teena unlocatable. Later, Arun reveals that Teena is an online friend of Jeevan, an old police commissioner who has come to investigate the case. On his order, the police search the flats but find nothing. After a few more hours, Mohan goes down the road and creates a scene that alarms the thugs, who promise him that they will find Teena, to locate the Goonda leader. Mohan, Arun, and the thugs forcefully enter the flat, pushing the watchman. The Sub-inspector witnesses the break-in but doesn\\'t interfere, thinking it to be the only way to locate Teena. The leader of the thugs waiting down meets the woman with The Goonda leader and apologizes to her as they cannot track the leader, which reveals that the woman was the one who ordered The thugs to beat and Kill The Goonda leader. Arun finds Teena Unconscious in the basement. With the help of Mohan, Teena, and Arun, and gets into the car with SI and speeds toward Hospital. Then the story is revealed. Teena, Arun, and Mohan, with the help of the woman who is Arun\\'s sister has made this kidnapping plan. It was done to extract money from Salim, who has harassed them all at some point in their life. They have robbed the money, which is ploy as to teach Salim a lesson. The woman has hidden Teena in a room, and when all the people enter the flat, Arun finds the guy who was assigned to carry out the transaction unconscious, and robbed the money. Mohan Kept the Money in the bag and took the car. The woman reveals the plan to the Goonda leader, who finds that the thugs waiting for him are part of the plan. They initially angered the SI but later learn that what they have done is right because they have just robbed the money, earned in illicit ways. The SI asks them to leave and happily calls his wife, walking down the road. ==Cast== * Alencier Ley Lopez as Sub-Inspector * Dheeraj Denny as Arun * Jins Baskar as Goonda leader in the flat * Yahiya as Mohan * Shini Ambalathodi as Mohan\\'s wife * Sruthi Susan Sam as Teena * Reshma Shenoy as Arun\\'s sister * Justin Varghese as one of the local thugs * Abhiram Suresh as Shaiju, an autorickshaw driver * Anoop Ramesh as Pop * Safeer Sait as the former Member of Parliament * Rajagopalan P as Salim * Khalfan as the Freak Boy * Anand Manmadhan as Subhair * Diljit Gore as Lawrence, the Facility Manager * Abhiram Suresh Unnithan as Shaiju * Gibin G Nair as Manu * Rahul Nair as Benoy * Asna as Mohan\\'s daughter * Santhosh Varghese as the Special Investigation Officer * Don Mathew as male reporter * Lydia Sebastian as female Reporter * Ebrahim Maheen as the Security Guard == Production == The film is produced by Vibezon Movies and is scheduled for release in 17 November 2017. Shooting was in 2016 March at a single location, Keston road, Thiruvananthapuram. It was 25 days night schedule as story takes place during night time. ==Music== The songs composed by Pramod Bhaskar and background score of the film composed by Mejo Joseph respectively while the lyrics are penned by M R Vibin and promo song written by Lawrence Fernandez. The songs featured in the film are sung by Deepak, Prashanth Prabhakar, Sangeetha Anand and Varsha S Nair. The soundtrack was officially released on 13 August 2018. The music of the Promo song is given by Assan Nidheesh SD and sung by Sithara Krishnakumar and Abhilash Kallayam. ===Tracks=== * Ee Theruvil : Prasanth Prabhakar, Sangeetha Ananth * Hey Thandanane : Sithara Krishnakumar, Abhilash Kallayam == Release == The film is released on 17 November 2017 in 34 theaters across Kerala. == Reviews == The Times of India reviewed the film with 3.5/5, as a \"convincing thriller with a line-up of mostly fresh faces.\" The Deccan Chronicle rated it 3.5/5 noting the film was \"A freshly brewed formula\". == References == Category:2017 films Category:2010s Malayalam-language films Category:Films directed by Sunil Ibrahim'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = df.iloc[1, 2] \n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: seve/y.parquetProcessing file: seve/x.parquetProcessing file: seve/z.parquet\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Text: 100%|██████████| 12914/12914 [00:06<00:00, 1910.21it/s]\n",
      "Replacing Titles: 100%|██████████| 12914/12914 [00:00<00:00, 254789.74it/s]\n",
      "Cleaning Text:  25%|██▌       | 11922/47649 [00:06<00:20, 1707.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 12914 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Text: 100%|██████████| 35525/35525 [00:18<00:00, 1931.85it/s]\n",
      "Replacing Titles: 100%|██████████| 35525/35525 [00:00<00:00, 261168.07it/s]\n",
      "Files:   0%|          | 0/3 [00:19<?, ?it/s][00:18<00:09, 1680.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 35525 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cleaning Text: 100%|██████████| 47649/47649 [00:27<00:00, 1713.82it/s]\n",
      "Replacing Titles: 100%|██████████| 47649/47649 [00:00<00:00, 254961.84it/s]\n",
      "Files:   0%|          | 0/3 [00:29<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 47649 rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Files:   0%|          | 0/3 [00:29<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count, Manager\n",
    "from html import unescape\n",
    "\n",
    "# Function to clean and process each row\n",
    "def clean_text(text):\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Join words back into cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Function to replace the title in the cleaned text\n",
    "def replace_title(row):\n",
    "    cleaned_text = row['cleaned_text']\n",
    "    title = unescape(row['title']).lower()\n",
    "    \n",
    "    # Ensure the whole title is properly replaced\n",
    "    cleaned_text = cleaned_text.replace('<title>', title)\n",
    "    \n",
    "    return cleaned_text\n",
    "\n",
    "# Function to process a single Parquet file\n",
    "def process_parquet_file(args):\n",
    "    file, queue = args\n",
    "    try:\n",
    "        print(f\"Processing file: {file}\")\n",
    "        \n",
    "        # Read Parquet file into DataFrame\n",
    "        df = pd.read_parquet(file)\n",
    "        \n",
    "        # Clean text\n",
    "        tqdm.pandas(desc=\"Cleaning Text\")  # Use tqdm with pandas\n",
    "        df['cleaned_text'] = df['text'].progress_apply(clean_text)\n",
    "        \n",
    "        # Replace title placeholders in cleaned text\n",
    "        tqdm.pandas(desc=\"Replacing Titles\")  # Use tqdm with pandas\n",
    "        df['cleaned_text'] = df.progress_apply(replace_title, axis=1)\n",
    "        \n",
    "        # Save processed DataFrame back to Parquet file (overwrite)\n",
    "        df.to_parquet(file, index=False)\n",
    "        \n",
    "        print(f\"Processed {len(df)} rows.\")\n",
    "        queue.put(1)  # Update progress bar\n",
    "        return file  # Return the file name for progress tracking\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "        queue.put(1)  # Update progress bar even if there is an error\n",
    "        return None  # Return None if there is an error\n",
    "\n",
    "# Function to process all Parquet files in a directory using multiprocessing\n",
    "def process_all_parquet_files(directory):\n",
    "    # List all Parquet files in the directory\n",
    "    parquet_files = glob.glob(directory + '/*.parquet')\n",
    "    \n",
    "    manager = Manager()\n",
    "    queue = manager.Queue()\n",
    "\n",
    "    # Use multiprocessing Pool to parallelize processing\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        # Create a tqdm progress bar for files\n",
    "        with tqdm(total=len(parquet_files), desc=\"Files\", position=0) as pbar:\n",
    "            results = []\n",
    "            for file in parquet_files:\n",
    "                results.append(pool.apply_async(process_parquet_file, args=((file, queue),)))\n",
    "\n",
    "            while not all(result.ready() for result in results):\n",
    "                pbar.update(queue.qsize())\n",
    "                queue = manager.Queue()\n",
    "\n",
    "            # Close and join the pool to ensure all processes complete\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "\n",
    "# Example usage: Process all Parquet files in a directory\n",
    "directory_path = 'seve/'\n",
    "process_all_parquet_files(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860524</td>\n",
       "      <td>L</td>\n",
       "      <td>L, or l, is the twelfth letter in the Latin al...</td>\n",
       "      <td>[ISO basic Latin letters]</td>\n",
       "      <td>l l twelfth letter latin alphabet used modern ...</td>\n",
       "      <td>[0.3376371, -0.10313419, -0.47920448, 0.036238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7167147</td>\n",
       "      <td>L &amp; N Marine Terminal Building</td>\n",
       "      <td>The L &amp; N Marine Terminal Building is a histor...</td>\n",
       "      <td>[Buildings and structures in Pensacola, Florid...</td>\n",
       "      <td>l n marine terminal building historic site pen...</td>\n",
       "      <td>[-0.004209465, -0.4288666, -0.32924867, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28519613</td>\n",
       "      <td>L (Ayumi Hamasaki EP)</td>\n",
       "      <td>L is the 50th single (51st overall) by Japanes...</td>\n",
       "      <td>[2010 singles, Oricon Weekly number-one singles]</td>\n",
       "      <td>l 50th single 51st overall japanese singer son...</td>\n",
       "      <td>[0.08933294, 0.02698402, -0.667453, 0.32261816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9893990</td>\n",
       "      <td>L (Death Note)</td>\n",
       "      <td>,Ohba, Tsugumi and Takeshi Obata. \"Character F...</td>\n",
       "      <td>[Martial artist characters in anime and manga,...</td>\n",
       "      <td>ohba tsugumi takeshi obata character file 2 l ...</td>\n",
       "      <td>[-0.012304991, -0.4061539, -0.7352755, 0.11444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36259475</td>\n",
       "      <td>L (French singer)</td>\n",
       "      <td>L is the stage name of Raphaële Lannadère,\"L\",...</td>\n",
       "      <td>[1981 births, French women singer-songwriters,...</td>\n",
       "      <td>l stage name raphaële lannadère l tôt ou tard ...</td>\n",
       "      <td>[0.26492855, -0.69320434, -0.86082757, 0.28035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364438</th>\n",
       "      <td>45466710</td>\n",
       "      <td>Lục Xuân Hưng</td>\n",
       "      <td>Lục Xuân Hưng (born 15 April 1995) is a Vietna...</td>\n",
       "      <td>[1995 births, Living people, Vietnamese footba...</td>\n",
       "      <td>lục xuân hưng born 15 april 1995 vietnamese fo...</td>\n",
       "      <td>[-0.14476362, -0.8220984, -1.316604, -0.499117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364439</th>\n",
       "      <td>15527229</td>\n",
       "      <td>Lục Yên district</td>\n",
       "      <td>Lục Yên is a rural district of Yên Bái provinc...</td>\n",
       "      <td>[Districts of Yên Bái province, Yên Bái province]</td>\n",
       "      <td>lục yên rural district yên bái province northe...</td>\n",
       "      <td>[0.09132685, -0.620817, -0.32133546, 0.2334157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364440</th>\n",
       "      <td>1858789</td>\n",
       "      <td>Lục bát</td>\n",
       "      <td>Lục bát (, ) is a traditional Vietnamese verse...</td>\n",
       "      <td>[Poetic forms, Vietnamese literary genres, Vie...</td>\n",
       "      <td>lục bát traditional vietnamese verse form hist...</td>\n",
       "      <td>[-0.14366665, 0.012986276, -0.38193414, 0.0137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364441</th>\n",
       "      <td>37953650</td>\n",
       "      <td>Lục súc tranh công</td>\n",
       "      <td>Lục súc tranh công (六畜爭功 \"The Quarrel of the S...</td>\n",
       "      <td>[Vietnamese poems]</td>\n",
       "      <td>lục súc tranh công 六畜爭功 quarrel six beasts cla...</td>\n",
       "      <td>[-0.43239307, -0.24961491, -0.24945787, 0.2566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364442</th>\n",
       "      <td>11325389</td>\n",
       "      <td>Lữ Mộng Lan</td>\n",
       "      <td>thumb|Lữ Mộng Lan Lieutenant General Lữ Mộng L...</td>\n",
       "      <td>[1927 births, 2021 deaths, Army of the Republi...</td>\n",
       "      <td>thumb lữ mộng lan lieutenant general lữ mộng l...</td>\n",
       "      <td>[0.3167757, -0.64930534, -0.6465167, 0.2288338...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364443 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                           title  \\\n",
       "0        4860524                               L   \n",
       "1        7167147  L & N Marine Terminal Building   \n",
       "2       28519613           L (Ayumi Hamasaki EP)   \n",
       "3        9893990                  L (Death Note)   \n",
       "4       36259475               L (French singer)   \n",
       "...          ...                             ...   \n",
       "364438  45466710                   Lục Xuân Hưng   \n",
       "364439  15527229                Lục Yên district   \n",
       "364440   1858789                         Lục bát   \n",
       "364441  37953650              Lục súc tranh công   \n",
       "364442  11325389                     Lữ Mộng Lan   \n",
       "\n",
       "                                                     text  \\\n",
       "0       L, or l, is the twelfth letter in the Latin al...   \n",
       "1       The L & N Marine Terminal Building is a histor...   \n",
       "2       L is the 50th single (51st overall) by Japanes...   \n",
       "3       ,Ohba, Tsugumi and Takeshi Obata. \"Character F...   \n",
       "4       L is the stage name of Raphaële Lannadère,\"L\",...   \n",
       "...                                                   ...   \n",
       "364438  Lục Xuân Hưng (born 15 April 1995) is a Vietna...   \n",
       "364439  Lục Yên is a rural district of Yên Bái provinc...   \n",
       "364440  Lục bát (, ) is a traditional Vietnamese verse...   \n",
       "364441  Lục súc tranh công (六畜爭功 \"The Quarrel of the S...   \n",
       "364442  thumb|Lữ Mộng Lan Lieutenant General Lữ Mộng L...   \n",
       "\n",
       "                                               categories  \\\n",
       "0                               [ISO basic Latin letters]   \n",
       "1       [Buildings and structures in Pensacola, Florid...   \n",
       "2        [2010 singles, Oricon Weekly number-one singles]   \n",
       "3       [Martial artist characters in anime and manga,...   \n",
       "4       [1981 births, French women singer-songwriters,...   \n",
       "...                                                   ...   \n",
       "364438  [1995 births, Living people, Vietnamese footba...   \n",
       "364439  [Districts of Yên Bái province, Yên Bái province]   \n",
       "364440  [Poetic forms, Vietnamese literary genres, Vie...   \n",
       "364441                                 [Vietnamese poems]   \n",
       "364442  [1927 births, 2021 deaths, Army of the Republi...   \n",
       "\n",
       "                                             cleaned_text  \\\n",
       "0       l l twelfth letter latin alphabet used modern ...   \n",
       "1       l n marine terminal building historic site pen...   \n",
       "2       l 50th single 51st overall japanese singer son...   \n",
       "3       ohba tsugumi takeshi obata character file 2 l ...   \n",
       "4       l stage name raphaële lannadère l tôt ou tard ...   \n",
       "...                                                   ...   \n",
       "364438  lục xuân hưng born 15 april 1995 vietnamese fo...   \n",
       "364439  lục yên rural district yên bái province northe...   \n",
       "364440  lục bát traditional vietnamese verse form hist...   \n",
       "364441  lục súc tranh công 六畜爭功 quarrel six beasts cla...   \n",
       "364442  thumb lữ mộng lan lieutenant general lữ mộng l...   \n",
       "\n",
       "                                               embeddings  \n",
       "0       [0.3376371, -0.10313419, -0.47920448, 0.036238...  \n",
       "1       [-0.004209465, -0.4288666, -0.32924867, -0.054...  \n",
       "2       [0.08933294, 0.02698402, -0.667453, 0.32261816...  \n",
       "3       [-0.012304991, -0.4061539, -0.7352755, 0.11444...  \n",
       "4       [0.26492855, -0.69320434, -0.86082757, 0.28035...  \n",
       "...                                                   ...  \n",
       "364438  [-0.14476362, -0.8220984, -1.316604, -0.499117...  \n",
       "364439  [0.09132685, -0.620817, -0.32133546, 0.2334157...  \n",
       "364440  [-0.14366665, 0.012986276, -0.38193414, 0.0137...  \n",
       "364441  [-0.43239307, -0.24961491, -0.24945787, 0.2566...  \n",
       "364442  [0.3167757, -0.64930534, -0.6465167, 0.2288338...  \n",
       "\n",
       "[364443 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean=df[\"cleaned_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         l l twelfth letter latin alphabet used modern ...\n",
       "1         l n marine terminal building historic site pen...\n",
       "2         l 50th single 51st overall japanese singer son...\n",
       "3         ohba tsugumi takeshi obata character file 2 l ...\n",
       "4         l stage name raphaële lannadère l tôt ou tard ...\n",
       "                                ...                        \n",
       "364438    lục xuân hưng born 15 april 1995 vietnamese fo...\n",
       "364439    lục yên rural district yên bái province northe...\n",
       "364440    lục bát traditional vietnamese verse form hist...\n",
       "364441    lục súc tranh công 六畜爭功 quarrel six beasts cla...\n",
       "364442    thumb lữ mộng lan lieutenant general lữ mộng l...\n",
       "Name: cleaned_text, Length: 364443, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a pre-trained BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a pre-trained BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|██████████| 364443/364443 [08:23<00:00, 723.47it/s] \n",
      "Embedding: 100%|██████████| 364443/364443 [3:08:59<00:00, 32.14it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0.3376371, -0.10313419, -0.47920448, 0.036238...\n",
      "1    [-0.004209465, -0.4288666, -0.32924867, -0.054...\n",
      "2    [0.08933294, 0.02698402, -0.667453, 0.32261816...\n",
      "3    [-0.012304991, -0.4061539, -0.7352755, 0.11444...\n",
      "4    [0.26492855, -0.69320434, -0.86082757, 0.28035...\n",
      "Name: embeddings, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = df['cleaned_text'].tolist()\n",
    "tokens = []\n",
    "\n",
    "# Tokenize the texts and prepare them for the model\n",
    "for text in tqdm(texts, desc=\"Tokenizing\"):\n",
    "    token = tokenizer.encode_plus(text, return_tensors=\"pt\", padding='max_length', truncation=True, max_length=512)\n",
    "    token = {k: v.to(device) for k, v in token.items()}\n",
    "    tokens.append(token)\n",
    "\n",
    "# Embed the tokens using the BERT model\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for token in tqdm(tokens, desc=\"Embedding\"):\n",
    "        output = model(**token)\n",
    "        embeddings.append(output.last_hidden_state[:, 0, :].squeeze().cpu().numpy())\n",
    "\n",
    "# Add embeddings to DataFrame\n",
    "df[\"embeddings\"] = embeddings\n",
    "\n",
    "# Print the embeddings\n",
    "print(df[\"embeddings\"].head())\n",
    "\n",
    "df.to_parquet('l.parquet', engine='pyarrow', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>categories</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4860524</td>\n",
       "      <td>L</td>\n",
       "      <td>L, or l, is the twelfth letter in the Latin al...</td>\n",
       "      <td>[ISO basic Latin letters]</td>\n",
       "      <td>l l twelfth letter latin alphabet used modern ...</td>\n",
       "      <td>[0.3376371, -0.10313419, -0.47920448, 0.036238...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7167147</td>\n",
       "      <td>L &amp; N Marine Terminal Building</td>\n",
       "      <td>The L &amp; N Marine Terminal Building is a histor...</td>\n",
       "      <td>[Buildings and structures in Pensacola, Florid...</td>\n",
       "      <td>l n marine terminal building historic site pen...</td>\n",
       "      <td>[-0.004209465, -0.4288666, -0.32924867, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28519613</td>\n",
       "      <td>L (Ayumi Hamasaki EP)</td>\n",
       "      <td>L is the 50th single (51st overall) by Japanes...</td>\n",
       "      <td>[2010 singles, Oricon Weekly number-one singles]</td>\n",
       "      <td>l 50th single 51st overall japanese singer son...</td>\n",
       "      <td>[0.08933294, 0.02698402, -0.667453, 0.32261816...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9893990</td>\n",
       "      <td>L (Death Note)</td>\n",
       "      <td>,Ohba, Tsugumi and Takeshi Obata. \"Character F...</td>\n",
       "      <td>[Martial artist characters in anime and manga,...</td>\n",
       "      <td>ohba tsugumi takeshi obata character file 2 l ...</td>\n",
       "      <td>[-0.012304991, -0.4061539, -0.7352755, 0.11444...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36259475</td>\n",
       "      <td>L (French singer)</td>\n",
       "      <td>L is the stage name of Raphaële Lannadère,\"L\",...</td>\n",
       "      <td>[1981 births, French women singer-songwriters,...</td>\n",
       "      <td>l stage name raphaële lannadère l tôt ou tard ...</td>\n",
       "      <td>[0.26492855, -0.69320434, -0.86082757, 0.28035...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364438</th>\n",
       "      <td>45466710</td>\n",
       "      <td>Lục Xuân Hưng</td>\n",
       "      <td>Lục Xuân Hưng (born 15 April 1995) is a Vietna...</td>\n",
       "      <td>[1995 births, Living people, Vietnamese footba...</td>\n",
       "      <td>lục xuân hưng born 15 april 1995 vietnamese fo...</td>\n",
       "      <td>[-0.14476362, -0.8220984, -1.316604, -0.499117...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364439</th>\n",
       "      <td>15527229</td>\n",
       "      <td>Lục Yên district</td>\n",
       "      <td>Lục Yên is a rural district of Yên Bái provinc...</td>\n",
       "      <td>[Districts of Yên Bái province, Yên Bái province]</td>\n",
       "      <td>lục yên rural district yên bái province northe...</td>\n",
       "      <td>[0.09132685, -0.620817, -0.32133546, 0.2334157...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364440</th>\n",
       "      <td>1858789</td>\n",
       "      <td>Lục bát</td>\n",
       "      <td>Lục bát (, ) is a traditional Vietnamese verse...</td>\n",
       "      <td>[Poetic forms, Vietnamese literary genres, Vie...</td>\n",
       "      <td>lục bát traditional vietnamese verse form hist...</td>\n",
       "      <td>[-0.14366665, 0.012986276, -0.38193414, 0.0137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364441</th>\n",
       "      <td>37953650</td>\n",
       "      <td>Lục súc tranh công</td>\n",
       "      <td>Lục súc tranh công (六畜爭功 \"The Quarrel of the S...</td>\n",
       "      <td>[Vietnamese poems]</td>\n",
       "      <td>lục súc tranh công 六畜爭功 quarrel six beasts cla...</td>\n",
       "      <td>[-0.43239307, -0.24961491, -0.24945787, 0.2566...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364442</th>\n",
       "      <td>11325389</td>\n",
       "      <td>Lữ Mộng Lan</td>\n",
       "      <td>thumb|Lữ Mộng Lan Lieutenant General Lữ Mộng L...</td>\n",
       "      <td>[1927 births, 2021 deaths, Army of the Republi...</td>\n",
       "      <td>thumb lữ mộng lan lieutenant general lữ mộng l...</td>\n",
       "      <td>[0.3167757, -0.64930534, -0.6465167, 0.2288338...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364443 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                           title  \\\n",
       "0        4860524                               L   \n",
       "1        7167147  L & N Marine Terminal Building   \n",
       "2       28519613           L (Ayumi Hamasaki EP)   \n",
       "3        9893990                  L (Death Note)   \n",
       "4       36259475               L (French singer)   \n",
       "...          ...                             ...   \n",
       "364438  45466710                   Lục Xuân Hưng   \n",
       "364439  15527229                Lục Yên district   \n",
       "364440   1858789                         Lục bát   \n",
       "364441  37953650              Lục súc tranh công   \n",
       "364442  11325389                     Lữ Mộng Lan   \n",
       "\n",
       "                                                     text  \\\n",
       "0       L, or l, is the twelfth letter in the Latin al...   \n",
       "1       The L & N Marine Terminal Building is a histor...   \n",
       "2       L is the 50th single (51st overall) by Japanes...   \n",
       "3       ,Ohba, Tsugumi and Takeshi Obata. \"Character F...   \n",
       "4       L is the stage name of Raphaële Lannadère,\"L\",...   \n",
       "...                                                   ...   \n",
       "364438  Lục Xuân Hưng (born 15 April 1995) is a Vietna...   \n",
       "364439  Lục Yên is a rural district of Yên Bái provinc...   \n",
       "364440  Lục bát (, ) is a traditional Vietnamese verse...   \n",
       "364441  Lục súc tranh công (六畜爭功 \"The Quarrel of the S...   \n",
       "364442  thumb|Lữ Mộng Lan Lieutenant General Lữ Mộng L...   \n",
       "\n",
       "                                               categories  \\\n",
       "0                               [ISO basic Latin letters]   \n",
       "1       [Buildings and structures in Pensacola, Florid...   \n",
       "2        [2010 singles, Oricon Weekly number-one singles]   \n",
       "3       [Martial artist characters in anime and manga,...   \n",
       "4       [1981 births, French women singer-songwriters,...   \n",
       "...                                                   ...   \n",
       "364438  [1995 births, Living people, Vietnamese footba...   \n",
       "364439  [Districts of Yên Bái province, Yên Bái province]   \n",
       "364440  [Poetic forms, Vietnamese literary genres, Vie...   \n",
       "364441                                 [Vietnamese poems]   \n",
       "364442  [1927 births, 2021 deaths, Army of the Republi...   \n",
       "\n",
       "                                             cleaned_text  \\\n",
       "0       l l twelfth letter latin alphabet used modern ...   \n",
       "1       l n marine terminal building historic site pen...   \n",
       "2       l 50th single 51st overall japanese singer son...   \n",
       "3       ohba tsugumi takeshi obata character file 2 l ...   \n",
       "4       l stage name raphaële lannadère l tôt ou tard ...   \n",
       "...                                                   ...   \n",
       "364438  lục xuân hưng born 15 april 1995 vietnamese fo...   \n",
       "364439  lục yên rural district yên bái province northe...   \n",
       "364440  lục bát traditional vietnamese verse form hist...   \n",
       "364441  lục súc tranh công 六畜爭功 quarrel six beasts cla...   \n",
       "364442  thumb lữ mộng lan lieutenant general lữ mộng l...   \n",
       "\n",
       "                                               embeddings  \n",
       "0       [0.3376371, -0.10313419, -0.47920448, 0.036238...  \n",
       "1       [-0.004209465, -0.4288666, -0.32924867, -0.054...  \n",
       "2       [0.08933294, 0.02698402, -0.667453, 0.32261816...  \n",
       "3       [-0.012304991, -0.4061539, -0.7352755, 0.11444...  \n",
       "4       [0.26492855, -0.69320434, -0.86082757, 0.28035...  \n",
       "...                                                   ...  \n",
       "364438  [-0.14476362, -0.8220984, -1.316604, -0.499117...  \n",
       "364439  [0.09132685, -0.620817, -0.32133546, 0.2334157...  \n",
       "364440  [-0.14366665, 0.012986276, -0.38193414, 0.0137...  \n",
       "364441  [-0.43239307, -0.24961491, -0.24945787, 0.2566...  \n",
       "364442  [0.3167757, -0.64930534, -0.6465167, 0.2288338...  \n",
       "\n",
       "[364443 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('ll.parquet', engine='pyarrow', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364443, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a pre-trained BERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 30522\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.get_vocab())\n",
    "\n",
    "# Print the vocabulary size\n",
    "print(f\"Vocabulary size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.2.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorrt\n",
    "# print(tensorrt.__version__)\n",
    "# # assert tensorrt.Builder(tensorrt.Logger())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model  # Add this line\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout, batch_first=True)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.d_model)\n",
    "        output = self.transformer(src, tgt)\n",
    "        return F.log_softmax(self.fc(output), dim=-1)\n",
    "\n",
    "# Initialize model\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "model = TransformerModel(vocab_size=32000, d_model=768, nhead=16, num_encoder_layers=12, num_decoder_layers=12, dim_feedforward=2048, dropout=0.25)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-06 18:04:43.206619: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-06 18:04:43.466833: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-06 18:04:44.010911: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout,batch_first=True)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.embedding(src)  # Embedding layer\n",
    "        tgt = self.embedding(tgt)  # Embedding layer\n",
    "        transformer_output = self.transformer(src, tgt)  # Transformer layers\n",
    "        logits = self.fc(transformer_output)  # Output layer\n",
    "        return logits\n",
    "\n",
    "\n",
    "vocab_size = 30522\n",
    "d_model = 768\n",
    "nhead = 16\n",
    "num_encoder_layers = 12\n",
    "num_decoder_layers = 12\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.25\n",
    "\n",
    "model = Model(vocab_size=vocab_size, d_model=d_model, nhead=nhead, num_encoder_layers=num_encoder_layers,\n",
    "                               num_decoder_layers=num_decoder_layers, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 207617850\n",
      "Total memory required for model parameters: 792.00 MB\n",
      "GPU memory available: 12288 MB\n",
      "The model will fit in the GPU memory.\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_params(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params\n",
    "\n",
    "# Function to calculate memory in MB\n",
    "def calculate_memory_in_MB(total_params):\n",
    "    memory_in_bytes = total_params * 4\n",
    "    memory_in_MB = memory_in_bytes / (1024 ** 2)  \n",
    "    return memory_in_MB\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = calculate_total_params(model)\n",
    "print(f'Total number of parameters: {total_params}')\n",
    "\n",
    "# Calculate memory\n",
    "memory_in_MB = calculate_memory_in_MB(total_params)\n",
    "print(f'Total memory required for model parameters: {memory_in_MB:.2f} MB')\n",
    "\n",
    "# Check if it fits in GPU\n",
    "gpu_memory_in_MB = 12 * 1024  # 12GB VRAM in MB\n",
    "print(f'GPU memory available: {gpu_memory_in_MB} MB')\n",
    "if memory_in_MB < gpu_memory_in_MB:\n",
    "    print(\"The model will fit in the GPU memory.\")\n",
    "else:\n",
    "    print(\"The model will not fit in the GPU memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_optimizer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LambdaLR\n\u001b[0;32m----> 5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mLamb(\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m      6\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m epoch: \u001b[38;5;241m0.95\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m epoch)\n\u001b[1;32m      7\u001b[0m criterion\u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch_optimizer as optim \n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "optimizer = optim.Lamb(model.parameters(), lr=0.001)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "criterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    eval_strategy=\"steps\",\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    output_dir=\"NLP/books/op\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into train and eval\n",
    "train, eval = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train = train['cleaned_text'].tolist()\n",
    "eval = eval['cleaned_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m train_sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m train:\n\u001b[0;32m---> 10\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     11\u001b[0m     train_sequences\u001b[38;5;241m.\u001b[39mextend(create_sequences(tokens, sequence_length))\n\u001b[1;32m     13\u001b[0m eval_sequences \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sequence_length = 256\n",
    "\n",
    "def create_sequences(text, seq_length):\n",
    "    return [text[i:i+seq_length] for i in range(0, len(text) - seq_length + 1)]\n",
    "\n",
    "train_sequences = []\n",
    "for text in tqdm(train, desc=\"Processing train data\"):\n",
    "    train_sequences.extend(create_sequences(text, sequence_length))\n",
    "\n",
    "eval_sequences = []\n",
    "for text in tqdm(eval, desc=\"Processing eval data\"):\n",
    "    eval_sequences.extend(create_sequences(text, sequence_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" )\n",
    "\n",
    "class Text(Dataset):\n",
    "    def __init__(self, sequences, vocab):\n",
    "        self.sequences = sequencesloss_fn \n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        input_seq = [self.vocab.get(word, self.vocab['<UNK>']) for word in sequence[:-1]]\n",
    "        target_seq = [self.vocab.get(word, self.vocab['<UNK>']) for word in sequence[1:]]\n",
    "        return torch.tensor(input_seq), torch.tensor(target_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<UNK>\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(vocab)  \u001b[38;5;66;03m# Add unknown token\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mText\u001b[49m(train_sequences, vocab)\n\u001b[1;32m      7\u001b[0m eval_dataset \u001b[38;5;241m=\u001b[39m Text(eval_sequences, vocab)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Text' is not defined"
     ]
    }
   ],
   "source": [
    "all_words = set(word for text in train + eval for word in text)\n",
    "vocab = {word: i for i, word in enumerate(all_words)}\n",
    "vocab['<UNK>'] = len(vocab)  # Add unknown token\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = Text(train_sequences, vocab)\n",
    "eval_dataset = Text(eval_sequences, vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32  \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = len(vocab)\n",
    "model = TransformerModel(vocab_size=vocab_size, d_model=768, nhead=16, num_encoder_layers=12, num_decoder_layers=12, dim_feedforward=2048, dropout=0.25)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "class WikiDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, \n",
    "                                  truncation=True, padding='max_length')\n",
    "        input_ids = encoding['input_ids'].squeeze()\n",
    "        return input_ids[:-1], input_ids[1:]\n",
    "\n",
    "# Setup\n",
    "dataset = WikiDataset(df['cleaned_text'].tolist(), tokenizer, max_length=128)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 11389/11389 [53:49<00:00,  3.53it/s, loss=8.2137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Average Loss: 8.6861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:   1%|          | 108/11389 [00:31<54:59,  3.42it/s, loss=8.7911]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[1;32m     28\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m---> 30\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     progress_bar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     33\u001b[0m avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Recreate the optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for src, tgt in progress_bar:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            output = model(src, tgt)\n",
    "            loss = criterion(output.view(-1, len(tokenizer)), tgt.view(-1))\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'lm_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miso/miniconda3/envs/nlp/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc850564259f4743ab0da18bcb3589e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/21 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fd9e60e359b4745b7049f004f9b7dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8013769 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611f0a52a15c486fb373b0f3f1bf749e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and grasping at life, watched doctors and nurses walk away from a field hospital Friday night after a Belgian medical team evacuated\n",
      "---\n",
      "Former secretary of state Hillary Clinton meets voters at a campaign rally in St. Louis on Saturday. (Melina Mara/The Washington Post)\n",
      "\n",
      "Democratic front-runner Hillary Clinton was ahead by a slim marg\n",
      "---\n",
      "The opinions expressed by columnists are their own and do not represent the views of Townhall.com.\n",
      "\n",
      "You have to give President Barack Obama credit for one thing: consistency. Nothing is ever his fault\n",
      "---\n",
      "BIGBANG is one of those musical entities that transcends language. It’s one of those rare groups that both innovates and defines the direction a genre takes. Covering a sound that includes hip hop, R&\n",
      "---\n",
      "WHAT?!??! I know. That’s what you’re saying right now.\n",
      "\n",
      "“WHAT?! DISNEY HAS A DONUT SUNDAE AND I DIDN’T KNOW ABOUT IT?!” How do I know you’re saying that? Because that’s exactly what I was saying when \n",
      "---\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 8013769\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"openwebtext\")\n",
    "\n",
    "# Access the data\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# Example: Print first few documents\n",
    "for i in range(5):\n",
    "    print(train_data[i][\"text\"][:200])  # Print first 200 characters of each document\n",
    "    print(\"---\")\n",
    "\n",
    "# Get dataset info\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbcfe831f39455ea999a2cc1f5353da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples in the dataset: 8013769\n",
      "Size of the first example (in characters): 5516\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"openwebtext\", split=\"train\")\n",
    "\n",
    "print(f\"Total number of examples in the dataset: {len(dataset)}\")\n",
    "print(f\"Size of the first example (in characters): {len(dataset[0]['text'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Replace URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '<URL>', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Replace numbers with <NUM> token\n",
    "        text = re.sub(r'\\b\\d+\\b', '<NUM>', text)\n",
    "        \n",
    "        # Remove special characters but keep some punctuation\n",
    "        text = re.sub(r'[^a-z\\s.,!?<>]', '', text)\n",
    "        \n",
    "        # Tokenize\n",
    "        words = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word not in stop_words]\n",
    "        \n",
    "        return ' '.join(words)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return \"\"  # Return empty string if processing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and grasping at life, watched doctors and nurses walk away from a field hospital Friday night after a Belgian medical team evacuated the area, saying it was concerned about security.\n",
      "\n",
      "The decision left CNN Chief Medical Correspondent Sanjay Gupta as the only doctor at the hospital to get the patients through the night.\n",
      "\n",
      "CNN initially reported, based on conversations with some of the doctors, that the United Nations ordered the B\n",
      "\n",
      "Cleaned text:\n",
      "portauprince , haiti cnn earthquake victims , writhing pain grasping life , watched doctors nurses walk away field hospital friday night belgian medical team evacuated area , saying concerned security . decision left cnn chief medical correspondent sanjay gupta doctor hospital get patients night . cnn initially reported , based conversations doctors , united nations ordered belgian first aid support team evacuate . however , belgian chief coordinator geert gijs , doctor hospital < > belgian medi\n"
     ]
    }
   ],
   "source": [
    "sample_text = dataset[0]['text']\n",
    "cleaned_sample = clean_text(sample_text)\n",
    "print(\"Original text:\")\n",
    "print(sample_text[:500])  # Print first 500 characters\n",
    "print(\"\\nCleaned text:\")\n",
    "print(cleaned_sample[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datasets import load_dataset\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    \n",
    "    # Remove special characters but keep some punctuation\n",
    "    text = re.sub(r'[^a-z\\s.,!?]', '', text)\n",
    "    \n",
    "    # Tokenize\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miso/miniconda3/envs/nlp/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c76a34cc8b460ba2773904ed3c9cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"openwebtext\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts:\n",
      "Port-au-Prince, Haiti (CNN) -- Earthquake victims, writhing in pain and grasping at life, watched do\n",
      "---\n",
      "Former secretary of state Hillary Clinton meets voters at a campaign rally in St. Louis on Saturday.\n",
      "---\n",
      "The opinions expressed by columnists are their own and do not represent the views of Townhall.com.\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "Cleaned texts:\n",
      "portauprince , haiti cnn earthquake victims , writhing pain grasping life , watched doctors nurses w\n",
      "---\n",
      "former secretary state hillary clinton meets voters campaign rally st. louis saturday . melina marat\n",
      "---\n",
      "opinions expressed columnists represent views townhall.com . give president barack obama credit one \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Take a small subset for testing\n",
    "small_set = dataset[:3]\n",
    "\n",
    "# Test the cleaning function\n",
    "print(\"Original texts:\")\n",
    "for text in small_set['text']:\n",
    "    print(text[:100])  # Print first 100 characters of each\n",
    "    print(\"---\")\n",
    "\n",
    "print(\"\\nCleaned texts:\")\n",
    "for text in small_set['text']:\n",
    "    cleaned = clean_text(text)\n",
    "    print(cleaned[:100])  # Print first 100 characters of each\n",
    "    print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned texts using multiprocessing:\n",
      "portauprince , haiti cnn earthquake victims , writhing pain grasping life , watched doctors nurses w\n",
      "---\n",
      "former secretary state hillary clinton meets voters campaign rally st. louis saturday . melina marat\n",
      "---\n",
      "opinions expressed columnists represent views townhall.com . give president barack obama credit one \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test multiprocessing\n",
    "def process_texts(texts):\n",
    "    return [clean_text(text) for text in texts]\n",
    "\n",
    "num_processes = multiprocessing.cpu_count() - 1  # Use all but one core\n",
    "    \n",
    "with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "        cleaned_texts = list(executor.map(clean_text, small_set['text']))\n",
    "    \n",
    "print(\"\\nCleaned texts using multiprocessing:\")\n",
    "for cleaned in cleaned_texts:\n",
    "        print(cleaned[:100])\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f502abfeee6484e93c4b6c829d5c293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples: 8013769\n",
      "Average size of each example (characters): 4955.12\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openwebtext\", split=\"train\")\n",
    "\n",
    "total_examples = len(dataset)\n",
    "sample_sizes = [len(text) for text in dataset[:1000]['text']]\n",
    "avg_size = sum(sample_sizes) / len(sample_sizes)\n",
    "\n",
    "print(f\"Total number of examples: {total_examples}\")\n",
    "print(f\"Average size of each example (characters): {avg_size:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended examples per chunk: 10580\n",
      "Total number of chunks: 758\n"
     ]
    }
   ],
   "source": [
    "target_chunk_size_mb = 100\n",
    "bytes_per_mb = 1024 * 1024\n",
    "characters_per_example = avg_size\n",
    "bytes_per_character = 2  # Assuming UTF-16 encoding\n",
    "\n",
    "examples_per_chunk = int((target_chunk_size_mb * bytes_per_mb) / (characters_per_example * bytes_per_character))\n",
    "\n",
    "total_chunks = (total_examples + examples_per_chunk - 1) // examples_per_chunk\n",
    "\n",
    "print(f\"Recommended examples per chunk: {examples_per_chunk}\")\n",
    "print(f\"Total number of chunks: {total_chunks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miso/miniconda3/envs/nlp/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/openwebtext\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a30a4f5a8d476fa05c9335cab3b059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 19 processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   1%|▏         | 10/758 [00:24<39:47,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_0.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   3%|▎         | 20/758 [00:52<42:46,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_1.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   4%|▍         | 30/758 [01:25<48:36,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_2.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   5%|▌         | 40/758 [01:59<48:32,  4.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_3.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   7%|▋         | 50/758 [02:35<51:26,  4.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_4.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   8%|▊         | 60/758 [03:12<54:08,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_5.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   9%|▉         | 70/758 [03:50<51:26,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_6.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  11%|█         | 80/758 [04:27<50:21,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_7.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  12%|█▏        | 90/758 [05:05<49:25,  4.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_8.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  13%|█▎        | 100/758 [05:44<49:29,  4.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_9.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  15%|█▍        | 110/758 [06:23<48:29,  4.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_10.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  16%|█▌        | 120/758 [07:02<47:18,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_11.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  17%|█▋        | 130/758 [07:41<48:10,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  18%|█▊        | 140/758 [08:20<49:02,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_13.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  20%|█▉        | 150/758 [08:59<46:50,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_14.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  21%|██        | 160/758 [09:39<45:33,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_15.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  22%|██▏       | 170/758 [10:19<45:49,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_16.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  24%|██▎       | 180/758 [10:57<44:16,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_17.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  25%|██▌       | 190/758 [11:36<43:04,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_18.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  26%|██▋       | 200/758 [12:16<43:55,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_19.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  28%|██▊       | 210/758 [12:56<43:37,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_20.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  29%|██▉       | 220/758 [13:35<41:49,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_21.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  30%|███       | 230/758 [14:15<41:10,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_22.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  32%|███▏      | 240/758 [14:53<39:58,  4.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_23.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  33%|███▎      | 250/758 [15:34<42:56,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_24.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  34%|███▍      | 260/758 [16:15<39:12,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_25.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  36%|███▌      | 270/758 [16:55<39:17,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_26.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  37%|███▋      | 280/758 [17:34<37:30,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_27.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  38%|███▊      | 290/758 [18:12<34:57,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_28.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  40%|███▉      | 300/758 [18:52<36:07,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_29.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  41%|████      | 310/758 [19:32<35:40,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_30.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  42%|████▏     | 320/758 [20:12<35:54,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_31.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  44%|████▎     | 330/758 [20:51<33:28,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_32.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  45%|████▍     | 340/758 [21:30<32:29,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_33.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  46%|████▌     | 350/758 [22:09<31:39,  4.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_34.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  47%|████▋     | 360/758 [22:49<32:40,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_35.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  49%|████▉     | 370/758 [23:30<33:36,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_36.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  50%|█████     | 380/758 [24:08<30:11,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_37.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  51%|█████▏    | 390/758 [24:48<30:19,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_38.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  53%|█████▎    | 400/758 [25:28<29:41,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_39.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  54%|█████▍    | 410/758 [26:07<27:44,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_40.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  55%|█████▌    | 420/758 [26:46<26:51,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_41.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  57%|█████▋    | 430/758 [27:25<26:37,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_42.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  58%|█████▊    | 440/758 [28:05<25:28,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_43.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  59%|█████▉    | 450/758 [28:44<24:09,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_44.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  61%|██████    | 460/758 [29:24<24:10,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_45.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  62%|██████▏   | 470/758 [30:04<24:17,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_46.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  63%|██████▎   | 480/758 [30:46<25:06,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_47.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  65%|██████▍   | 490/758 [31:26<22:57,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_48.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  66%|██████▌   | 500/758 [32:05<20:29,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_49.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  67%|██████▋   | 510/758 [32:45<21:12,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_50.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  69%|██████▊   | 520/758 [33:24<19:30,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_51.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  70%|██████▉   | 530/758 [34:05<20:10,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_52.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  71%|███████   | 540/758 [34:45<18:29,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_53.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  73%|███████▎  | 550/758 [35:27<18:46,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_54.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  74%|███████▍  | 560/758 [36:07<17:15,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_55.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  75%|███████▌  | 570/758 [36:46<15:02,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_56.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  77%|███████▋  | 580/758 [37:26<15:11,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_57.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  78%|███████▊  | 590/758 [38:07<14:27,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_58.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  79%|███████▉  | 600/758 [38:47<13:44,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_59.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  80%|████████  | 610/758 [39:28<13:11,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_60.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  82%|████████▏ | 620/758 [40:08<12:03,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_61.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  83%|████████▎ | 630/758 [40:48<11:10,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_62.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  84%|████████▍ | 640/758 [41:28<09:57,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_63.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  86%|████████▌ | 650/758 [42:07<08:53,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_64.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  87%|████████▋ | 660/758 [42:47<08:05,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_65.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  88%|████████▊ | 670/758 [43:27<07:49,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_66.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  90%|████████▉ | 680/758 [44:07<06:45,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_67.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  91%|█████████ | 690/758 [44:47<05:50,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_68.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  92%|█████████▏| 700/758 [45:28<05:07,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_69.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  94%|█████████▎| 710/758 [46:08<04:11,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_70.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  95%|█████████▍| 720/758 [46:50<03:29,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_71.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  96%|█████████▋| 730/758 [47:31<02:30,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_72.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  98%|█████████▊| 740/758 [48:11<01:33,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_73.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  99%|█████████▉| 750/758 [48:51<00:40,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_74.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 758/758 [49:21<00:00,  3.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned_openwebtext_chunk_75.parquet\n",
      "Processing complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = re.sub(r'[^a-z\\s.,!?]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def process_text(text):\n",
    "    return clean_text(text)\n",
    "\n",
    "def process_chunk(chunk):\n",
    "    df = pd.DataFrame(chunk)\n",
    "    with ProcessPoolExecutor(max_workers=num_processes) as executor:\n",
    "        df['cleaned_text'] = list(executor.map(process_text, df['text']))\n",
    "    return df\n",
    "\n",
    "def save_merged_chunk(merged_chunk, merged_chunk_id):\n",
    "    filename = f\"cleaned_openwebtext_chunk_{merged_chunk_id}.parquet\"\n",
    "    merged_chunk.to_parquet(filename, index=False)\n",
    "    print(f\"Saved {filename}\")\n",
    "\n",
    "dataset = load_dataset(\"openwebtext\", split=\"train\")\n",
    "chunk_size = 10580\n",
    "num_processes = max(1, math.floor(multiprocessing.cpu_count() * 0.8))\n",
    "chunks_per_merge = 10\n",
    "\n",
    "print(f\"Using {num_processes} processes\")\n",
    "\n",
    "merged_chunk = pd.DataFrame()\n",
    "\n",
    "for i in tqdm(range(0, len(dataset), chunk_size), desc=\"Processing chunks\"):\n",
    "    chunk = dataset[i:i+chunk_size]\n",
    "    processed_chunk = process_chunk(chunk)\n",
    "    merged_chunk = pd.concat([merged_chunk, processed_chunk], ignore_index=True)\n",
    "    \n",
    "    if (i // chunk_size + 1) % chunks_per_merge == 0 or i + chunk_size >= len(dataset):\n",
    "        filename = f\"cleaned_openwebtext_chunk_{i // (chunk_size * chunks_per_merge)}.parquet\"\n",
    "        merged_chunk.to_parquet(filename, index=False)\n",
    "        print(f\"Saved {filename}\")\n",
    "        merged_chunk = pd.DataFrame()\n",
    "\n",
    "print(\"Processing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105800 entries, 0 to 105799\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   text          105800 non-null  object\n",
      " 1   cleaned_text  105800 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "\n",
      "First few rows:\n",
      "                                                text  \\\n",
      "0  Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n",
      "1  Former secretary of state Hillary Clinton meet...   \n",
      "2  The opinions expressed by columnists are their...   \n",
      "3  BIGBANG is one of those musical entities that ...   \n",
      "4  WHAT?!??! I know. That’s what you’re saying ri...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  portauprince , haiti cnn earthquake victims , ...  \n",
      "1  former secretary state hillary clinton meets v...  \n",
      "2  opinions expressed columnists represent views ...  \n",
      "3  bigbang one musical entities transcends langua...  \n",
      "4  ? ! ? ? ! know . thats youre saying right . ? ...  \n",
      "\n",
      "Basic statistics:\n",
      "                                                     text  \\\n",
      "count                                              105800   \n",
      "unique                                             105800   \n",
      "top     Port-au-Prince, Haiti (CNN) -- Earthquake vict...   \n",
      "freq                                                    1   \n",
      "\n",
      "                                             cleaned_text  \n",
      "count                                              105800  \n",
      "unique                                             105800  \n",
      "top     portauprince , haiti cnn earthquake victims , ...  \n",
      "freq                                                    1  \n",
      "\n",
      "Sample of cleaned text:\n",
      "40815     un wants host patent summit deal smartphone pa...\n",
      "100263    steve watson infowars.net thursday , dec , int...\n",
      "16209     al jazeera arabic launched freeview platform n...\n",
      "31910     soldiers germanys bundeswehr take part trainin...\n",
      "23805     seems week weve talked jamie benn loui eriksso...\n",
      "Name: cleaned_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load a single Parquet file\n",
    "df = pd.read_parquet(\"cleaned_openwebtext_chunk_0.parquet\")\n",
    "\n",
    "# Display basic information about the DataFrame\n",
    "print(df.info())\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Display some basic statistics\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# If you want to see a sample of the cleaned text\n",
    "print(\"\\nSample of cleaned text:\")\n",
    "print(df['cleaned_text'].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer...\n",
      "Training tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 76/76 [05:11<00:00,  4.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Saving tokenizer...\n",
      "Tokenizer training complete.\n",
      "Testing tokenizer...\n",
      "\n",
      "Original: This is a test sentence.\n",
      "Tokens: ['[UNK]', 'his', 'is', 'a', 'test', 'sentence', '.']\n",
      "IDs: [0, 5578, 63, 9, 572, 5182, 7]\n",
      "\n",
      "Original: Hugging Face tokenizers are fast and efficient.\n",
      "Tokens: ['[UNK]', 'u', 'gging', '[UNK]', 'ace', 'token', 'izers', 'are', 'fast', 'and', 'efficient', '.']\n",
      "IDs: [0, 29, 5361, 0, 238, 8132, 13258, 156, 1426, 111, 4786, 7]\n",
      "\n",
      "Original: Let's see how it handles unseen words and punctuation!\n",
      "Tokens: ['[UNK]', 'et', '[UNK]', 's', 'see', 'how', 'it', 'handles', 'unseen', 'words', 'and', 'punctuation', '!']\n",
      "IDs: [0, 78, 0, 27, 344, 613, 49, 12471, 19068, 1661, 111, 33976, 5]\n",
      "\n",
      "Original: The quick brown fox jumps over the lazy dog.\n",
      "Tokens: ['[UNK]', 'he', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "IDs: [0, 176, 1422, 2880, 2640, 15036, 599, 402, 11094, 2974, 7]\n",
      "\n",
      "Tokenizer training complete. You can now use 'huggingface_tokenizer.json' for tokenization in your training process.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "def process_parquet_files(directory):\n",
    "    all_files = glob.glob(f\"{directory}/*.parquet\")\n",
    "    for file in tqdm(all_files, desc=\"Processing files\"):\n",
    "        df = pd.read_parquet(file)\n",
    "        yield from df['cleaned_text']\n",
    "\n",
    "parquet_directory = \"openweb/\"\n",
    "\n",
    "print(\"Initializing tokenizer...\")\n",
    "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "trainer = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], \n",
    "                     vocab_size=100000)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "print(\"Training tokenizer...\")\n",
    "tokenizer.train_from_iterator(process_parquet_files(parquet_directory), trainer=trainer)\n",
    "\n",
    "print(\"Saving tokenizer...\")\n",
    "tokenizer.save(\"100k.json\")\n",
    "\n",
    "print(\"Tokenizer training complete.\")\n",
    "\n",
    "print(\"Testing tokenizer...\")\n",
    "test_sentences = [\n",
    "    \"This is a test sentence.\",\n",
    "    \"Hugging Face tokenizers are fast and efficient.\",\n",
    "    \"Let's see how it handles unseen words and punctuation!\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    encoded = tokenizer.encode(sentence)\n",
    "    print(f\"\\nOriginal: {sentence}\")\n",
    "    print(f\"Tokens: {encoded.tokens}\")\n",
    "    print(f\"IDs: {encoded.ids}\")\n",
    "\n",
    "print(\"\\nTokenizer training complete. You can now use 'huggingface_tokenizer.json' for tokenization in your training process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original: This is a test sentence.\n",
      "Tokens: ['[UNK]', 'his', 'is', 'a', 'test', 'sentence', '.']\n",
      "IDs: [0, 5578, 63, 9, 572, 5182, 7]\n",
      "Decoded: his is a test sentence .\n",
      "\n",
      "Original: Machine learning models are powerful tools for natural language processing.\n",
      "Tokens: ['[UNK]', 'achine', 'learning', 'models', 'are', 'powerful', 'tools', 'for', 'natural', 'language', 'processing', '.']\n",
      "IDs: [0, 50316, 3092, 3689, 156, 2818, 3433, 144, 2115, 2247, 5668, 7]\n",
      "Decoded: achine learning models are powerful tools for natural language processing .\n",
      "\n",
      "Original: The quick brown fox jumps over the lazy dog.\n",
      "Tokens: ['[UNK]', 'he', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "IDs: [0, 176, 1422, 2880, 2640, 15036, 599, 402, 11094, 2974, 7]\n",
      "Decoded: he quick brown fox jumps over the lazy dog .\n",
      "\n",
      "Original: Tokenization is an important step in preparing text data for language models.\n",
      "Tokens: ['[UNK]', 'oken', 'ization', 'is', 'an', 'important', 'step', 'in', 'preparing', 'text', 'data', 'for', 'language', 'models', '.']\n",
      "IDs: [0, 17794, 1180, 63, 42, 1003, 1207, 35, 7127, 2053, 834, 144, 2247, 3689, 7]\n",
      "Decoded: oken ization is an important step in preparing text data for language models .\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"100k.json\")\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"This is a test sentence.\",\n",
    "    \"Machine learning models are powerful tools for natural language processing.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Tokenization is an important step in preparing text data for language models.\"\n",
    "]\n",
    "\n",
    "# Tokenize and print results\n",
    "for sentence in test_sentences:\n",
    "    encoded = tokenizer.encode(sentence)\n",
    "    print(f\"\\nOriginal: {sentence}\")\n",
    "    print(f\"Tokens: {encoded.tokens}\")\n",
    "    print(f\"IDs: {encoded.ids}\")\n",
    "    \n",
    "    # Decode back to text\n",
    "    decoded = tokenizer.decode(encoded.ids)\n",
    "    print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer...\n",
      "Training tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 76/76 [05:34<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Saving tokenizer...\n",
      "Tokenizer training complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "def process_parquet_files(directory):\n",
    "    all_files = glob.glob(f\"{directory}/*.parquet\")\n",
    "    for file in tqdm(all_files, desc=\"Processing files\"):\n",
    "        df = pd.read_parquet(file)\n",
    "        yield from df['cleaned_text']\n",
    "\n",
    "parquet_directory = \"openweb/\"\n",
    "\n",
    "print(\"Initializing tokenizer...\")\n",
    "tokenizer = Tokenizer(WordPiece(unk_token=\"[UNK]\"))\n",
    "trainer = WordPieceTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"], \n",
    "                           vocab_size=50000)\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "print(\"Training tokenizer...\")\n",
    "tokenizer.train_from_iterator(process_parquet_files(parquet_directory), trainer=trainer)\n",
    "\n",
    "print(\"Saving tokenizer...\")\n",
    "tokenizer.save(\"wordpiece_50k.json\")\n",
    "\n",
    "print(\"Tokenizer training complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original: This is a test sentence.\n",
      "Tokens: ['[UNK]', 'is', 'a', 'test', 'sentence', '.']\n",
      "IDs: [0, 432, 9, 879, 5598, 7]\n",
      "Decoded: is a test sentence .\n",
      "\n",
      "Original: Machine learning models are powerful tools for natural language processing.\n",
      "Tokens: ['[UNK]', 'learning', 'models', 'are', 'powerful', 'tools', 'for', 'natural', 'language', 'processing', '.']\n",
      "IDs: [0, 3345, 3947, 967, 3035, 3719, 348, 2435, 2486, 6454, 7]\n",
      "Decoded: learning models are powerful tools for natural language processing .\n",
      "\n",
      "Original: The quick brown fox jumps over the lazy dog.\n",
      "Tokens: ['[UNK]', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
      "IDs: [0, 1543, 3122, 3134, 15322, 803, 537, 12308, 2464, 7]\n",
      "Decoded: quick brown fox jumps over the lazy dog .\n",
      "\n",
      "Original: Tokenization is an important step in preparing text data for language models.\n",
      "Tokens: ['[UNK]', 'is', 'an', 'important', 'step', 'in', 'preparing', 'text', 'data', 'for', 'language', 'models', '.']\n",
      "IDs: [0, 432, 165, 1104, 1282, 94, 7657, 2258, 943, 348, 2486, 3947, 7]\n",
      "Decoded: is an important step in preparing text data for language models .\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"wordpiece_50k.json\")\n",
    "\n",
    "# Test sentences\n",
    "test_sentences = [\n",
    "    \"This is a test sentence.\",\n",
    "    \"Machine learning models are powerful tools for natural language processing.\",\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Tokenization is an important step in preparing text data for language models.\"\n",
    "]\n",
    "\n",
    "# Tokenize and print results\n",
    "for sentence in test_sentences:\n",
    "    encoded = tokenizer.encode(sentence)\n",
    "    print(f\"\\nOriginal: {sentence}\")\n",
    "    print(f\"Tokens: {encoded.tokens}\")\n",
    "    print(f\"IDs: {encoded.ids}\")\n",
    "    \n",
    "    # Decode back to text\n",
    "    decoded = tokenizer.decode(encoded.ids)\n",
    "    print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torchmetrics import Perplexity, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "device=torch.device('cuda')\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        mask = self.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
    "        output = self.transformer_encoder(src, mask)\n",
    "        return self.fc(output)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "model = TransformerModel(vocab_size=32000, d_model=512, nhead=16, num_layers=12, dim_feedforward=2048, dropout=0.25)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a sample batch:\n",
      "Batch shape: torch.Size([32, 512])\n",
      "\n",
      "Sample sequence:\n",
      "saints lost yet another top rated manager english club despite grim outlook , claude pu els arrival may fil lip club need guardian writers predicted position th nb necessarily jacob stein bergs prediction average writers tips last seasons position th odds win league via odds checker risk sounding callous , reached stage summer wouldnt feel without upheaval southampton . third successive year exit door st marys swung open far much liking although accustomed talent drain , unreasonable wonder may season begin feel strain . bulld og next bus qu ets premier league signings watch read maur icio pochett inos departure tottenham sparked sale five players combined . m , sharks detected blood ronald ko eman lured everton . losing dutch man overseen two excellent seasons tough take two reasons . punct ured celebr atory atmosphere generated southampton securing highest premier league position , mention finishing three points champions league spots . second , say place food chain snatch ing sixth place west ham qualifying group stage europa league final day season still enough keep manager away club finished five places points ? sad io man joined liverpool deal worth victor w any ama linked pochett ino tottenham , graz iano pell accepted move china , fans forgiven mis giv ings scope south am ptons ambition given particularly active transfer market . context , looks claude pu el , ko em ans replacement , accepted hospital pass . hold moment . think back . although leicester city re defined art cram ming humble pie unsuspecting critics throat , southampton provided original template responded predictions relegation finishing seventh ko em ans first season . despite selling nathaniel cly ne morgan schneider lin liverpool united respectively last summer , bounced back poor first half season . careful . southampton repeatedly stressed model dependent manages . laid strong foundations thriving youth academy , clear identity , solid infrastructure training ground . equally , however , success pitch largely depend work manager quality senior players . pu el intriguing appointment , coach appears right fit southampton given regarded france builder want play attractive sensible football develop young players , arrives fresh productive fouryear spell nice , almost guided champions league last season . end settled europa league qualification , two points lyon monaco , finishing fourth club whose resources modest suggests pu el knows construct coherent team . one notable achievements last season coax best hat em ben ar fa , pu el also took lyon last four champions league six years ago , beating real madrid french champions bor de aux losing bayern munich . however , critics yearold , whose previous four jobs france , hold failure win title lyon . seven consecutive titles joined pip ped bor de aux first season marseille second . left reputation diminished . southampton expected win premier league , course , pu el inherited promising squad , albeit one could reinforcements attack . everything goes plan , southampton capable least maintaining position top half reaching knockout stages europa league , assuming draw kind . pu el may need time\n",
      "\n",
      "Input shape: torch.Size([32, 511])\n",
      "Target shape: torch.Size([32, 511])\n",
      "\n",
      "Sample input:\n",
      "saints lost yet another top rated manager english club despite grim outlook , claude pu els arrival may fil lip club need guardian writers predicted position th nb necessarily jacob stein bergs prediction average writers tips last seasons position th odds win league via odds checker risk sounding callous , reached stage summer wouldnt feel without upheaval southampton . third successive year exit door st marys swung open far much liking although accustomed talent drain , unreasonable wonder may season begin feel strain . bulld og next bus qu ets premier league signings watch read maur icio pochett inos departure tottenham sparked sale five players combined . m , sharks detected blood ronald ko eman lured everton . losing dutch man overseen two excellent seasons tough take two reasons . punct ured celebr atory atmosphere generated southampton securing highest premier league position , mention finishing three points champions league spots . second , say place food chain snatch ing sixth place west ham qualifying group stage europa league final day season still enough keep manager away club finished five places points ? sad io man joined liverpool deal worth victor w any ama linked pochett ino tottenham , graz iano pell accepted move china , fans forgiven mis giv ings scope south am ptons ambition given particularly active transfer market . context , looks claude pu el , ko em ans replacement , accepted hospital pass . hold moment . think back . although leicester city re defined art cram ming humble pie unsuspecting critics throat , southampton provided original template responded predictions relegation finishing seventh ko em ans first season . despite selling nathaniel cly ne morgan schneider lin liverpool united respectively last summer , bounced back poor first half season . careful . southampton repeatedly stressed model dependent manages . laid strong foundations thriving youth academy , clear identity , solid infrastructure training ground . equally , however , success pitch largely depend work manager quality senior players . pu el intriguing appointment , coach appears right fit southampton given regarded france builder want play attractive sensible football develop young players , arrives fresh productive fouryear spell nice , almost guided champions league last season . end settled europa league qualification , two points lyon monaco , finishing fourth club whose resources modest suggests pu el knows construct coherent team . one notable achievements last season coax best hat em ben ar fa , pu el also took lyon last four champions league six years ago , beating real madrid french champions bor de aux losing bayern munich . however , critics yearold , whose previous four jobs france , hold failure win title lyon . seven consecutive titles joined pip ped bor de aux first season marseille second . left reputation diminished . southampton expected win premier league , course , pu el inherited promising squad , albeit one could reinforcements attack . everything goes plan , southampton capable least maintaining position top half reaching knockout stages europa league , assuming draw kind . pu el may need\n",
      "\n",
      "Sample target:\n",
      "lost yet another top rated manager english club despite grim outlook , claude pu els arrival may fil lip club need guardian writers predicted position th nb necessarily jacob stein bergs prediction average writers tips last seasons position th odds win league via odds checker risk sounding callous , reached stage summer wouldnt feel without upheaval southampton . third successive year exit door st marys swung open far much liking although accustomed talent drain , unreasonable wonder may season begin feel strain . bulld og next bus qu ets premier league signings watch read maur icio pochett inos departure tottenham sparked sale five players combined . m , sharks detected blood ronald ko eman lured everton . losing dutch man overseen two excellent seasons tough take two reasons . punct ured celebr atory atmosphere generated southampton securing highest premier league position , mention finishing three points champions league spots . second , say place food chain snatch ing sixth place west ham qualifying group stage europa league final day season still enough keep manager away club finished five places points ? sad io man joined liverpool deal worth victor w any ama linked pochett ino tottenham , graz iano pell accepted move china , fans forgiven mis giv ings scope south am ptons ambition given particularly active transfer market . context , looks claude pu el , ko em ans replacement , accepted hospital pass . hold moment . think back . although leicester city re defined art cram ming humble pie unsuspecting critics throat , southampton provided original template responded predictions relegation finishing seventh ko em ans first season . despite selling nathaniel cly ne morgan schneider lin liverpool united respectively last summer , bounced back poor first half season . careful . southampton repeatedly stressed model dependent manages . laid strong foundations thriving youth academy , clear identity , solid infrastructure training ground . equally , however , success pitch largely depend work manager quality senior players . pu el intriguing appointment , coach appears right fit southampton given regarded france builder want play attractive sensible football develop young players , arrives fresh productive fouryear spell nice , almost guided champions league last season . end settled europa league qualification , two points lyon monaco , finishing fourth club whose resources modest suggests pu el knows construct coherent team . one notable achievements last season coax best hat em ben ar fa , pu el also took lyon last four champions league six years ago , beating real madrid french champions bor de aux losing bayern munich . however , critics yearold , whose previous four jobs france , hold failure win title lyon . seven consecutive titles joined pip ped bor de aux first season marseille second . left reputation diminished . southampton expected win premier league , course , pu el inherited promising squad , albeit one could reinforcements attack . everything goes plan , southampton capable least maintaining position top half reaching knockout stages europa league , assuming draw kind . pu el may need time\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "class StreamingLLMDataset(IterableDataset):\n",
    "    def __init__(self, parquet_directory, tokenizer, seq_length):\n",
    "        self.parquet_directory = parquet_directory\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.files = glob.glob(f\"{parquet_directory}/*.parquet\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in self.files:\n",
    "            df = pd.read_parquet(file)\n",
    "            for text in df['cleaned_text']:\n",
    "                tokens = self.tokenizer.encode(text).ids\n",
    "                if len(tokens) >= self.seq_length:\n",
    "                    yield torch.tensor(tokens[:self.seq_length], dtype=torch.long)\n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    return DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "# Usage\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"32k.json\")\n",
    "dataset = StreamingLLMDataset(\"openweb/\", tokenizer, seq_length=512)\n",
    "dataloader = create_dataloader(dataset, batch_size=32)\n",
    "\n",
    "# Print a batch\n",
    "print(\"Printing a sample batch:\")\n",
    "for batch in dataloader:\n",
    "    print(\"Batch shape:\", batch.shape)\n",
    "    print(\"\\nSample sequence:\")\n",
    "    print(tokenizer.decode(batch[0].tolist()))\n",
    "    \n",
    "    # Demonstrate how to get input and target from this batch\n",
    "    input_seq = batch[:, :-1]\n",
    "    target_seq = batch[:, 1:]\n",
    "    print(\"\\nInput shape:\", input_seq.shape)\n",
    "    print(\"Target shape:\", target_seq.shape)\n",
    "    print(\"\\nSample input:\")\n",
    "    print(tokenizer.decode(input_seq[0].tolist()))\n",
    "    print(\"\\nSample target:\")\n",
    "    print(tokenizer.decode(target_seq[0].tolist()))\n",
    "    break  # Only print the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/1000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 104\u001b[0m\n\u001b[1;32m     95\u001b[0m dataset \u001b[38;5;241m=\u001b[39m StreamingLLMDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenweb/\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m     97\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgs\u001b[39m\u001b[38;5;124m'\u001b[39m, (), {\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1000\u001b[39m,  \u001b[38;5;66;03m# Adjust based on your dataset size\u001b[39;00m\n\u001b[1;32m    102\u001b[0m })()\n\u001b[0;32m--> 104\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, tokenizer, args)\u001b[0m\n\u001b[1;32m     42\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(input_seq)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# output shape: [batch_size, seq_len, vocab_size]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# target_seq shape: [batch_size, seq_len]\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[43mtarget_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     47\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     48\u001b[0m scaler\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch_optimizer as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "def train(model, dataset, tokenizer, args):\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=args.batch_size)\n",
    "\n",
    "    optimizer = optim.Lamb(model.parameters(), lr=args.lr)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        progress_bar = tqdm(enumerate(dataloader), total=args.steps_per_epoch, desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        for i, tokens in progress_bar:\n",
    "            if i >= args.steps_per_epoch:\n",
    "                break\n",
    "            \n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            \n",
    "            with autocast():\n",
    "                output = model(input_seq)\n",
    "                # output shape: [batch_size, seq_len, vocab_size]\n",
    "                # target_seq shape: [batch_size, seq_len]\n",
    "                loss = criterion(output.view(-1, output.size(-1)), target_seq.view(-1))\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "        avg_loss = total_loss / args.steps_per_epoch\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        print(f\"Time: {time.time() - start_time:.2f}s\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "    # Evaluation code (if needed)\n",
    "\n",
    "    # After training, calculate perplexity on a sample of data\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 5  # number of batches to evaluate on\n",
    "    with torch.no_grad():\n",
    "        for i, tokens in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.view(-1, output.size(-1)), target_seq.contiguous().view(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    perplexity = torch.exp(torch.tensor(total_loss / num_batches))\n",
    "    print(f\"Perplexity on sample: {perplexity.item():.2f}\")\n",
    "\n",
    "# Usage\n",
    "tokenizer = Tokenizer.from_file(\"32k.json\")\n",
    "model = TransformerModel(vocab_size=tokenizer.get_vocab_size(), d_model=512, nhead=16, num_layers=12, dim_feedforward=2048, dropout=0.25)\n",
    "dataset = StreamingLLMDataset(\"openweb/\", tokenizer, seq_length=512)\n",
    "\n",
    "args = type('Args', (), {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 1e-4,\n",
    "    \"epochs\": 10,\n",
    "    \"steps_per_epoch\": 1000,  # Adjust based on your dataset size\n",
    "})()\n",
    "\n",
    "train(model, dataset, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1000/1000 [01:45<00:00,  9.50it/s, loss=9.8417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Time: 105.21s\n",
      "Average Loss: 10.2372\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1000/1000 [01:44<00:00,  9.61it/s, loss=9.4545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Time: 104.11s\n",
      "Average Loss: 9.6832\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1000/1000 [01:44<00:00,  9.60it/s, loss=9.3478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Time: 104.12s\n",
      "Average Loss: 9.4742\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1000/1000 [01:44<00:00,  9.61it/s, loss=9.3094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Time: 104.08s\n",
      "Average Loss: 9.4142\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1000/1000 [01:43<00:00,  9.69it/s, loss=9.2887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Time: 103.22s\n",
      "Average Loss: 9.3865\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1000/1000 [01:43<00:00,  9.62it/s, loss=9.2747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Time: 103.98s\n",
      "Average Loss: 9.3665\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1000/1000 [01:43<00:00,  9.63it/s, loss=9.2564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Time: 103.88s\n",
      "Average Loss: 9.3481\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1000/1000 [01:42<00:00,  9.73it/s, loss=9.2346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Time: 102.75s\n",
      "Average Loss: 9.3298\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1000/1000 [01:38<00:00, 10.13it/s, loss=9.2193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Time: 98.67s\n",
      "Average Loss: 9.3119\n",
      "New best model saved!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1000/1000 [01:35<00:00, 10.45it/s, loss=9.2039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Time: 95.71s\n",
      "Average Loss: 9.2959\n",
      "New best model saved!\n",
      "\n",
      "Perplexity on sample: 10145.65\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import torch_optimizer as optim\n",
    "from tokenizers import Tokenizer\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        mask = self.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
    "        output = self.transformer_encoder(src, mask)\n",
    "        return self.fc(output)\n",
    "\n",
    "class StreamingLLMDataset(IterableDataset):\n",
    "    def __init__(self, parquet_directory, tokenizer, seq_length):\n",
    "        self.parquet_directory = parquet_directory\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.files = glob.glob(f\"{parquet_directory}/*.parquet\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in self.files:\n",
    "            df = pd.read_parquet(file)\n",
    "            for text in df['cleaned_text']:\n",
    "                tokens = self.tokenizer.encode(text).ids\n",
    "                if len(tokens) >= self.seq_length:\n",
    "                    yield torch.tensor(tokens[:self.seq_length], dtype=torch.long)\n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    return DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "def train(model, dataset, tokenizer, args):\n",
    "    model = model.to(device)\n",
    "    dataloader = create_dataloader(dataset, args.batch_size)\n",
    "\n",
    "    optimizer = optim.Lamb(model.parameters(), lr=args.lr)\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "    scaler = GradScaler()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        progress_bar = tqdm(enumerate(dataloader), total=args.steps_per_epoch, desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        for i, tokens in progress_bar:\n",
    "            if i >= args.steps_per_epoch:\n",
    "                break\n",
    "            \n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            \n",
    "            with autocast():\n",
    "                output = model(input_seq)\n",
    "                loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % args.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            total_loss += loss.item() * args.gradient_accumulation_steps\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item() * args.gradient_accumulation_steps:.4f}'})\n",
    "\n",
    "        avg_loss = total_loss / args.steps_per_epoch\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        print(f\"Time: {time.time() - start_time:.2f}s\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 5\n",
    "    with torch.no_grad():\n",
    "        for i, tokens in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    perplexity = torch.exp(torch.tensor(total_loss / num_batches))\n",
    "    print(f\"Perplexity on sample: {perplexity.item():.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = Tokenizer.from_file(\"32k.json\")\n",
    "    model = TransformerModel(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=8,\n",
    "        dim_feedforward=1024,\n",
    "        dropout=0.25\n",
    "    )\n",
    "    dataset = StreamingLLMDataset(\"openweb/\", tokenizer, seq_length=512)\n",
    "\n",
    "    args = type('Args', (), {\n",
    "        \"batch_size\": 16,\n",
    "        \"lr\": 5e-5,\n",
    "        \"epochs\": 10,\n",
    "        \"steps_per_epoch\": 1000,\n",
    "        \"gradient_accumulation_steps\": 4 \n",
    "    })()\n",
    "\n",
    "    train(model, dataset, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 192\u001b[0m\n\u001b[1;32m    183\u001b[0m dataset \u001b[38;5;241m=\u001b[39m StreamingLLMDataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenweb/\u001b[39m\u001b[38;5;124m\"\u001b[39m, tokenizer, seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[1;32m    185\u001b[0m args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArgs\u001b[39m\u001b[38;5;124m'\u001b[39m, (), {\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m5e-5\u001b[39m,\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgradient_accumulation_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m4\u001b[39m\n\u001b[1;32m    190\u001b[0m })()\n\u001b[0;32m--> 192\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, tokenizer, args)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Split dataset into train and validation\u001b[39;00m\n\u001b[1;32m     82\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.9\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset))\n\u001b[0;32m---> 83\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m train_size\n\u001b[1;32m     84\u001b[0m train_dataset, val_dataset \u001b[38;5;241m=\u001b[39m random_split(dataset, [train_size, val_size])\n\u001b[1;32m     86\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m create_dataloader(train_dataset, args\u001b[38;5;241m.\u001b[39mbatch_size)\n",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36mStreamingLLMDataset.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 73\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__len__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfiles)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pandas/io/parquet.py:274\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    268\u001b[0m     path,\n\u001b[1;32m    269\u001b[0m     filesystem,\n\u001b[1;32m    270\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    271\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    272\u001b[0m )\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     result \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pyarrow/parquet/core.py:3003\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, read_dictionary, memory_map, buffer_size, partitioning, filesystem, filters, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2992\u001b[0m         \u001b[38;5;66;03m# TODO test that source is not a directory or a list\u001b[39;00m\n\u001b[1;32m   2993\u001b[0m         dataset \u001b[38;5;241m=\u001b[39m ParquetFile(\n\u001b[1;32m   2994\u001b[0m             source, metadata\u001b[38;5;241m=\u001b[39mmetadata, read_dictionary\u001b[38;5;241m=\u001b[39mread_dictionary,\n\u001b[1;32m   2995\u001b[0m             memory_map\u001b[38;5;241m=\u001b[39mmemory_map, buffer_size\u001b[38;5;241m=\u001b[39mbuffer_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3000\u001b[0m             thrift_container_size_limit\u001b[38;5;241m=\u001b[39mthrift_container_size_limit,\n\u001b[1;32m   3001\u001b[0m         )\n\u001b[0;32m-> 3003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_pandas_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   3007\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to get the legacy behaviour is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3008\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated as of pyarrow 8.0.0, and the legacy implementation will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3009\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe removed in a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3010\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   3012\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_prefixes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.11/site-packages/pyarrow/parquet/core.py:2631\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.read\u001b[0;34m(self, columns, use_threads, use_pandas_metadata)\u001b[0m\n\u001b[1;32m   2623\u001b[0m         index_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2624\u001b[0m             col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m _get_pandas_index_columns(metadata)\n\u001b[1;32m   2625\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mdict\u001b[39m)\n\u001b[1;32m   2626\u001b[0m         ]\n\u001b[1;32m   2627\u001b[0m         columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2628\u001b[0m             \u001b[38;5;28mlist\u001b[39m(columns) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(index_columns) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(columns))\n\u001b[1;32m   2629\u001b[0m         )\n\u001b[0;32m-> 2631\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filter_expression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2633\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_threads\u001b[49m\n\u001b[1;32m   2634\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2636\u001b[0m \u001b[38;5;66;03m# if use_pandas_metadata, restore the pandas metadata (which gets\u001b[39;00m\n\u001b[1;32m   2637\u001b[0m \u001b[38;5;66;03m# lost if doing a specific `columns` selection in to_table)\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_pandas_metadata:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, IterableDataset, random_split\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import torch_optimizer as optim\n",
    "from tokenizers import Tokenizer\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, batch_size, is_train=True):\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=is_train, num_workers=4, pin_memory=True)\n",
    "\n",
    "def train(model, dataset, tokenizer, args):\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Split dataset into train and validation\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = create_dataloader(train_dataset, args.batch_size)\n",
    "    val_loader = create_dataloader(val_dataset, args.batch_size, is_train=False)\n",
    "\n",
    "    optimizer = optim.Lamb(model.parameters(), lr=args.lr)\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=args.lr, epochs=args.epochs, steps_per_epoch=len(train_loader))\n",
    "    scaler = GradScaler()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(args.epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        for i, tokens in progress_bar:\n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            \n",
    "            with autocast():\n",
    "                output = model(input_seq)\n",
    "                loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "                loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (i + 1) % args.gradient_accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scheduler.step()\n",
    "\n",
    "            total_loss += loss.item() * args.gradient_accumulation_steps\n",
    "            progress_bar.set_postfix({'loss': f'{loss.item() * args.gradient_accumulation_steps:.4f}'})\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for tokens in val_loader:\n",
    "                tokens = tokens.to(device)\n",
    "                input_seq = tokens[:, :-1]\n",
    "                target_seq = tokens[:, 1:]\n",
    "                output = model(input_seq)\n",
    "                loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "        print(f\"Time: {time.time() - start_time:.2f}s\")\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_val_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f'checkpoint_epoch_{epoch}.pth')\n",
    "            print(\"New best model saved!\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for tokens in val_loader:\n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    perplexity = torch.exp(torch.tensor(total_loss / len(val_loader)))\n",
    "    print(f\"Final Perplexity: {perplexity.item():.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = Tokenizer.from_file(\"32k.json\")\n",
    "    model = TransformerModel(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=8,\n",
    "        dim_feedforward=1024,\n",
    "        dropout=0.25\n",
    "    )\n",
    "    dataset = StreamingLLMDataset(\"openweb/\", tokenizer, seq_length=512)\n",
    "\n",
    "    args = type('Args', (), {\n",
    "        \"batch_size\": 16,\n",
    "        \"lr\": 5e-5,\n",
    "        \"epochs\": 20,\n",
    "        \"gradient_accumulation_steps\": 4\n",
    "    })()\n",
    "\n",
    "    train(model, dataset, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000:   4%|▎         | 36640/1001722 [26:29<12:18:49, 21.77it/s, loss=9.1586]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import torch_optimizer as optim\n",
    "from tokenizers import Tokenizer\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        mask = self.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
    "        output = self.transformer_encoder(src, mask)\n",
    "        return self.fc(output)\n",
    "\n",
    "class StreamingLLMDataset(IterableDataset):\n",
    "    def __init__(self, parquet_directory, tokenizer, seq_length):\n",
    "        self.parquet_directory = parquet_directory\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.files = glob.glob(f\"{parquet_directory}/*.parquet\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in self.files:\n",
    "            df = pd.read_parquet(file)\n",
    "            for text in df['cleaned_text']:\n",
    "                tokens = self.tokenizer.encode(text).ids\n",
    "                if len(tokens) >= self.seq_length:\n",
    "                    yield torch.tensor(tokens[:self.seq_length], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(pd.read_parquet(file)) for file in self.files)\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "def train(model, dataset, tokenizer, args, start_epoch=0):\n",
    "    model = model.to(device)\n",
    "    dataloader = create_dataloader(dataset, args.batch_size)\n",
    "\n",
    "    optimizer = optim.Lamb(model.parameters(), lr=args.lr)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=args.epochs // 10, T_mult=2)\n",
    "    scaler = GradScaler()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    if os.path.exists('checkpoint.pth'):\n",
    "        checkpoint = torch.load('checkpoint.pth')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_loss = checkpoint['best_loss']\n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "    log_file = open('training_log.txt', 'a')\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, args.epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "            for i, tokens in progress_bar:\n",
    "                tokens = tokens.to(device)\n",
    "                input_seq = tokens[:, :-1]\n",
    "                target_seq = tokens[:, 1:]\n",
    "                \n",
    "                with autocast():\n",
    "                    output = model(input_seq)\n",
    "                    loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "                    loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if (i + 1) % args.gradient_accumulation_steps == 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                total_loss += loss.item() * args.gradient_accumulation_steps\n",
    "                progress_bar.set_postfix({'loss': f'{loss.item() * args.gradient_accumulation_steps:.4f}'})\n",
    "\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            scheduler.step()\n",
    "            \n",
    "            log_message = f\"Epoch {epoch+1}/{args.epochs}, Time: {time.time() - start_time:.2f}s, Average Loss: {avg_loss:.4f}\"\n",
    "            print(log_message)\n",
    "            log_file.write(log_message + '\\n')\n",
    "            log_file.flush()\n",
    "            \n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_loss': best_loss,\n",
    "                }\n",
    "                torch.save(checkpoint, 'checkpoint.pth')\n",
    "                print(\"New best model saved!\")\n",
    "            \n",
    "            # Save checkpoint every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_loss': best_loss,\n",
    "                }\n",
    "                torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "            \n",
    "            print()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted. Saving checkpoint...\")\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_loss': best_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, 'interrupt_checkpoint.pth')\n",
    "\n",
    "    log_file.close()\n",
    "\n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = min(100, len(dataloader))  # Evaluate on at most 100 batches\n",
    "    with torch.no_grad():\n",
    "        for i, tokens in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    perplexity = torch.exp(torch.tensor(total_loss / num_batches))\n",
    "    print(f\"Final Perplexity: {perplexity.item():.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = Tokenizer.from_file(\"32k.json\")\n",
    "    model = TransformerModel(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_layers=8,\n",
    "        dim_feedforward=1024,\n",
    "        dropout=0.25\n",
    "    )\n",
    "    dataset = StreamingLLMDataset(\"openweb/\", tokenizer, seq_length=512)\n",
    "\n",
    "    args = type('Args', (), {\n",
    "        \"batch_size\": 8,\n",
    "        \"lr\": 1e-4,\n",
    "        \"epochs\": 2000,\n",
    "        \"gradient_accumulation_steps\": 16\n",
    "    })()\n",
    "\n",
    "    train(model, dataset, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   8%|▊         | 20784/250431 [16:32<3:36:22, 17.69it/s, loss=8.7278]  "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, IterableDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "import torch_optimizer as optim\n",
    "from tokenizers import Tokenizer\n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, nhead, num_layers, dim_feedforward, dropout):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        mask = self.generate_square_subsequent_mask(src.size(1)).to(src.device)\n",
    "        output = self.transformer_encoder(src, mask)\n",
    "        return self.fc(output)\n",
    "\n",
    "class StreamingLLMDataset(IterableDataset):\n",
    "    def __init__(self, parquet_directory, tokenizer, seq_length):\n",
    "        self.parquet_directory = parquet_directory\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.files = glob.glob(f\"{parquet_directory}/*.parquet\")\n",
    "\n",
    "    def __iter__(self):\n",
    "        for file in self.files:\n",
    "            df = pd.read_parquet(file)\n",
    "            for text in df['cleaned_text']:\n",
    "                tokens = self.tokenizer.encode(text).ids\n",
    "                if len(tokens) >= self.seq_length:\n",
    "                    yield torch.tensor(tokens[:self.seq_length], dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(len(pd.read_parquet(file)) for file in self.files)\n",
    "\n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    return DataLoader(dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "def train(model, dataset, tokenizer, args, start_epoch=0):\n",
    "    model = model.to(device)\n",
    "    dataloader = create_dataloader(dataset, args.batch_size)\n",
    "\n",
    "    optimizer = optim.Lamb(model.parameters(), lr=args.lr)\n",
    "    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=args.epochs // 10, T_mult=2)\n",
    "    scaler = GradScaler()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    if os.path.exists('checkpoint.pth'):\n",
    "        checkpoint = torch.load('checkpoint.pth')\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_loss = checkpoint['best_loss']\n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "    log_file = open('training_log.txt', 'a')\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, args.epochs):\n",
    "            model.train()\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "            \n",
    "            progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "            for i, tokens in progress_bar:\n",
    "                tokens = tokens.to(device)\n",
    "                input_seq = tokens[:, :-1]\n",
    "                target_seq = tokens[:, 1:]\n",
    "                \n",
    "                with autocast():\n",
    "                    output = model(input_seq)\n",
    "                    loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "                    loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                if (i + 1) % args.gradient_accumulation_steps == 0:\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "                total_loss += loss.item() * args.gradient_accumulation_steps\n",
    "                progress_bar.set_postfix({'loss': f'{loss.item() * args.gradient_accumulation_steps:.4f}'})\n",
    "\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            scheduler.step()\n",
    "            \n",
    "            log_message = f\"Epoch {epoch+1}/{args.epochs}, Time: {time.time() - start_time:.2f}s, Average Loss: {avg_loss:.4f}\"\n",
    "            print(log_message)\n",
    "            log_file.write(log_message + '\\n')\n",
    "            log_file.flush()\n",
    "            \n",
    "            if avg_loss < best_loss:\n",
    "                best_loss = avg_loss\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_loss': best_loss,\n",
    "                }\n",
    "                torch.save(checkpoint, 'checkpoint.pth')\n",
    "                print(\"New best model saved!\")\n",
    "            \n",
    "            # Save checkpoint every 10 epochs\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                checkpoint = {\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'best_loss': best_loss,\n",
    "                }\n",
    "                torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "            \n",
    "            print()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted. Saving checkpoint...\")\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_loss': best_loss,\n",
    "        }\n",
    "        torch.save(checkpoint, 'interrupt_checkpoint.pth')\n",
    "\n",
    "    log_file.close()\n",
    "\n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = min(100, len(dataloader)) \n",
    "    with torch.no_grad():\n",
    "        for i, tokens in enumerate(dataloader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            tokens = tokens.to(device)\n",
    "            input_seq = tokens[:, :-1]\n",
    "            target_seq = tokens[:, 1:]\n",
    "            output = model(input_seq)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), target_seq.reshape(-1))\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    perplexity = torch.exp(torch.tensor(total_loss / num_batches))\n",
    "    print(f\"Final Perplexity: {perplexity.item():.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = Tokenizer.from_file(\"32k.json\")\n",
    "    model = TransformerModel(\n",
    "        vocab_size=tokenizer.get_vocab_size(),\n",
    "        d_model=256,\n",
    "        nhead=8,\n",
    "        num_layers=8,\n",
    "        dim_feedforward=512,\n",
    "        dropout=0.25\n",
    "    )\n",
    "    dataset = StreamingLLMDataset(\"openweb/\", tokenizer, seq_length=256)\n",
    "\n",
    "    args = type('Args', (), {\n",
    "        \"batch_size\": 32,\n",
    "        \"lr\": 5e-4,\n",
    "        \"epochs\": 50,\n",
    "        \"gradient_accumulation_steps\": 16\n",
    "    })()\n",
    "\n",
    "    train(model, dataset, tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
